{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimator API\n",
    "\n",
    "tf.estimator.Estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo: housing Price Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shutil.rmtree(\"outdir\", ignore_errors = True) # start fresh each time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_master': '', '_evaluation_master': '', '_is_chief': True, '_task_id': 0, '_num_worker_replicas': 1, '_keep_checkpoint_max': 5, '_train_distribute': None, '_tf_random_seed': None, '_task_type': 'worker', '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_save_summary_steps': 100, '_log_step_count_steps': 100, '_num_ps_replicas': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f56bb51ee10>, '_session_config': None, '_global_id_in_cluster': 0, '_model_dir': 'outdir'}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into outdir/model.ckpt.\n",
      "INFO:tensorflow:step = 1, loss = 9290000.0\n",
      "INFO:tensorflow:global_step/sec: 662.232\n",
      "INFO:tensorflow:step = 101, loss = 144242.62 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 1104.52\n",
      "INFO:tensorflow:step = 201, loss = 142023.2 (0.090 sec)\n",
      "INFO:tensorflow:global_step/sec: 862.647\n",
      "INFO:tensorflow:step = 301, loss = 140171.67 (0.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 975.937\n",
      "INFO:tensorflow:step = 401, loss = 138553.88 (0.102 sec)\n",
      "INFO:tensorflow:global_step/sec: 1222.44\n",
      "INFO:tensorflow:step = 501, loss = 137101.47 (0.084 sec)\n",
      "INFO:tensorflow:global_step/sec: 1293.54\n",
      "INFO:tensorflow:step = 601, loss = 135774.66 (0.075 sec)\n",
      "INFO:tensorflow:global_step/sec: 1196.3\n",
      "INFO:tensorflow:step = 701, loss = 134547.12 (0.087 sec)\n",
      "INFO:tensorflow:global_step/sec: 332.744\n",
      "INFO:tensorflow:step = 801, loss = 133400.81 (0.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 882.759\n",
      "INFO:tensorflow:step = 901, loss = 132322.62 (0.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 951.873\n",
      "INFO:tensorflow:step = 1001, loss = 131302.42 (0.104 sec)\n",
      "INFO:tensorflow:global_step/sec: 1537.61\n",
      "INFO:tensorflow:step = 1101, loss = 130332.56 (0.065 sec)\n",
      "INFO:tensorflow:global_step/sec: 1099.47\n",
      "INFO:tensorflow:step = 1201, loss = 129406.88 (0.091 sec)\n",
      "INFO:tensorflow:global_step/sec: 1060.88\n",
      "INFO:tensorflow:step = 1301, loss = 128520.266 (0.094 sec)\n",
      "INFO:tensorflow:global_step/sec: 922.318\n",
      "INFO:tensorflow:step = 1401, loss = 127668.76 (0.108 sec)\n",
      "INFO:tensorflow:global_step/sec: 887.732\n",
      "INFO:tensorflow:step = 1501, loss = 126848.92 (0.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 899.191\n",
      "INFO:tensorflow:step = 1601, loss = 126057.62 (0.106 sec)\n",
      "INFO:tensorflow:global_step/sec: 953.099\n",
      "INFO:tensorflow:step = 1701, loss = 125292.484 (0.112 sec)\n",
      "INFO:tensorflow:global_step/sec: 1099.98\n",
      "INFO:tensorflow:step = 1801, loss = 124551.555 (0.084 sec)\n",
      "INFO:tensorflow:global_step/sec: 1107.12\n",
      "INFO:tensorflow:step = 1901, loss = 123832.59 (0.090 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into outdir/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 123141.125.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.linear.LinearRegressor at 0x7f56bb51ec50>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train_input_fn():\n",
    "    features = {\"sq_footage\": [1000, 2000, 3000, 1000, 2000, 3000],\n",
    "                \"type\":       [\"house\",\"house\",\"house\",\"apt\",\"apt\",\"apt\"]}\n",
    "    labels =                  [ 500, 1000, 1500,  700, 1300, 1900]   # in thousands\n",
    "    return features, labels\n",
    "\n",
    "featcols = [\n",
    "    tf.feature_column.numeric_column(\"sq_footage\"),\n",
    "    tf.feature_column.categorical_column_with_vocabulary_list(\"type\", [\"house\", \"apt\"])\n",
    "]\n",
    "\n",
    "model = tf.estimator.LinearRegressor(featcols, \"outdir\")\n",
    "\n",
    "model.train(train_input_fn, steps=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Input graph does not use tf.data.Dataset or contain a QueueRunner. That means predict yields forever. This is probably a mistake.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from outdir/model.ckpt-2000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "{'predictions': array([844.07806], dtype=float32)}\n",
      "{'predictions': array([871.82715], dtype=float32)}\n",
      "{'predictions': array([1414.5388], dtype=float32)}\n",
      "{'predictions': array([1442.2878], dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "def predict_input_fn():\n",
    "    features = {\"sq_footage\": [1500, 1500, 2500, 2500],\n",
    "                \"type\": [\"house\", \"apt\", \"house\", \"apt\"]}\n",
    "    return features\n",
    "\n",
    "predictions = model.predict(predict_input_fn)\n",
    "\n",
    "print(next(predictions))\n",
    "print(next(predictions))\n",
    "print(next(predictions))\n",
    "print(next(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkpointing\n",
    "\n",
    "Estimators automatically checkpoint training\n",
    "```\n",
    "model = tf.estimator.LinearRegressor(featcols, \"./model_trained\")\n",
    "\n",
    "model.train(train_input_fn, steps=2000)\n",
    "```\n",
    "\n",
    "`%ls model_trained`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint\r\n",
      "events.out.tfevents.1548844028.jxw-Inspiron-7460\r\n",
      "graph.pbtxt\r\n",
      "model.ckpt-1.data-00000-of-00001\r\n",
      "model.ckpt-1.index\r\n",
      "model.ckpt-1.meta\r\n",
      "model.ckpt-2000.data-00000-of-00001\r\n",
      "model.ckpt-2000.index\r\n",
      "model.ckpt-2000.meta\r\n"
     ]
    }
   ],
   "source": [
    "%ls outdir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training on in-memory datasets\n",
    "\n",
    "In memory data: usually numpy arrays or Pandas dataframes - you can use them directly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![train_input](train_input.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Train on large datasets with Dataset API\n",
    "\n",
    "![](TextLineDataset.png)\n",
    "![](TextLineDataset2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Big jobs, Distributed training\n",
    "\n",
    "![](train_and_evaluate.png)\n",
    "![](run_config.png)\n",
    "![](TrainSpec.png)\n",
    "![](EvalSpec.png)\n",
    "![](recap.png)\n",
    "\n",
    "Shuffling is even more important in distributed training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>**Real World ML Models**</center>\n",
    "\n",
    "|Problem|Solution|\n",
    "|:-:|:-:|\n",
    "|Out of memory data| Use the Dataset API|\n",
    "|Distribution | Use train_and_evaluate|\n",
    "|Need to evaluate during training | Use train_and_evaluate + TensorBoard|\n",
    "|Deployments that scale | Use serving input function|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serving Input Function\n",
    "\n",
    "Serving and training-time inputs are often very different\n",
    "\n",
    "![](serving_input_function.png)\n",
    "![](json_predict.png)\n",
    "![](json_predict2.png)\n",
    "\n",
    "**decode JPEGs(Base64 binary string)**\n",
    "![](decodes_jpegs.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
