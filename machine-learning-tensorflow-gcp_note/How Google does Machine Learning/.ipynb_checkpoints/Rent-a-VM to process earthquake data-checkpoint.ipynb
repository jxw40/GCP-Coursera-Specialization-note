{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Username\n",
    "google2198582_student@qwiklabs.net\n",
    "Password\n",
    "fRF7BgpKn\n",
    "GCP Project ID\n",
    "qwiklabs-gcp-b939ca40fb95f134\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rent-a-VM to process earthquake data\n",
    "\n",
    "## Overview\n",
    "\n",
    "Duration is 1 min\n",
    "\n",
    "In this lab, you spin up a virtual machine, configure its security, access it remotely, and then carry out the steps of an ingest-transform-and-publish data pipeline manually.\n",
    "\n",
    "### What you learn\n",
    "\n",
    "In this lab, you:\n",
    "\n",
    "* Create a Compute Engine instance with the necessary Access and Security\n",
    "\n",
    "* SSH into the instance\n",
    "\n",
    "* Install the software package Git (for source code version control)\n",
    "\n",
    "* Ingest data into a Compute Engine instance\n",
    "\n",
    "* Transform data on the Compute Engine instance\n",
    "\n",
    "* Store the transformed data on Cloud Storage\n",
    "\n",
    "* Publish Cloud Storage data to the web\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Duration is 1 min\n",
    "\n",
    "In this lab, you spin up a virtual machine, install software on it, and use it to do scientific data processing. We do not recommend that you work with Compute Engine instances at such a low-level, but you can!\n",
    "\n",
    "In this lab, you will use Google Cloud Platform in a manner similar to the way you likely use clusters today. Spinning up a virtual machine and running your jobs on it is the closest you can get to working with the public cloud as simply rented infrastructure. It doesn't take advantage of the other benefits that Google Cloud Platform provides -- namely the ability to forget about infrastructure and work with your scientific computation problems simply as software that requires to be run.\n",
    "\n",
    "You will ingest real-time earthquake data published by the United States Geological Survey (USGS) and create maps that look like this:\n",
    "\n",
    "b3b64f0a8d7eedde.png\n",
    "\n",
    "## Setup\n",
    "\n",
    "For each lab, you get a new GCP project and set of resources for a fixed time at no cost.\n",
    "\n",
    "1. Make sure you signed into Qwiklabs using an incognito window.\n",
    "\n",
    "2. Note the lab's access time (for example, img/time.png and make sure you can finish in that time block.\n",
    "> There is no pause feature. You can restart if needed, but you have to start at the beginning.\n",
    "\n",
    "3. When ready, click img/start_lab.png.\n",
    "\n",
    "4. Note your lab credentials. You will use them to sign in to Cloud Platform Console. img/open_console.png\n",
    "\n",
    "5. Click Open Google Console.\n",
    "\n",
    "6. Click Use another account and copy/paste credentials for this lab into the prompts.\n",
    "> If you use other credentials, you'll get errors or incur charges.\n",
    "\n",
    "7. Accept the terms and skip the recovery resource page.\n",
    "> Do not click End unless you are finished with the lab or want to restart it. This clears your work and removes the project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Compute Engine instance with the necessary API access\n",
    "\n",
    "Duration is 4 min\n",
    "\n",
    "To create a Compute Engine instance:\n",
    "\n",
    "### Step 1\n",
    "Browse to https://cloud.google.com/\n",
    "\n",
    "### Step 2\n",
    "Click on Go To Console.\n",
    "\n",
    "### Step 3\n",
    "Click on the Navigation menu (three horizontal lines):\n",
    "\n",
    "aab385b15ea9c7f4.png\n",
    "\n",
    "### Step 4\n",
    "Select Compute Engine.\n",
    "\n",
    "### Step 5\n",
    "Click Create and wait for a form to load. You will need to change some options on the form that comes up.\n",
    "\n",
    "### Step 6\n",
    "Change Identify and API access for the Compute Engine default service account to Allow full access to all Cloud APIs:\n",
    "\n",
    "8ab244f9cffa6198.png\n",
    "\n",
    "### Step 7\n",
    "Now, click Create"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SSH into the instance\n",
    "\n",
    "Duration is 2 min\n",
    "\n",
    "You can remotely access your Compute Engine instance using Secure Shell (SSH):\n",
    "\n",
    "### Step 1\n",
    "Click on SSH:\n",
    "\n",
    "e4d9f3244db5ba38.png\n",
    "\n",
    "Note:\n",
    "\n",
    "SSH keys are automatically transferred, and that you can ssh directly from the browser, with no extra software needed.\n",
    "\n",
    "### Step 2\n",
    "To find some information about the Compute Engine instance, type the following into the command-line:\n",
    "\n",
    "```\n",
    "cat /proc/cpuinfo\n",
    "```\n",
    "\n",
    "## Install software\n",
    "\n",
    "Duration is 2 min\n",
    "\n",
    "### Step 1\n",
    "Type the following into command-line:\n",
    "```\n",
    "sudo apt-get update\n",
    "sudo apt-get -y -qq install git\n",
    "```\n",
    "\n",
    "### Step 2\n",
    "Verify that git is now installed\n",
    "```\n",
    "git --version\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingest USGS data\n",
    "\n",
    "Duration is 3 min\n",
    "\n",
    "### Step 1\n",
    "On the command-line, type:\n",
    "```\n",
    "git clone https://github.com/GoogleCloudPlatform/training-data-analyst\n",
    "```\n",
    "This clones the code repo.\n",
    "\n",
    "### Step 2\n",
    "Navigate to the folder corresponding to this lab:\n",
    "```\n",
    "cd training-data-analyst/courses/machine_learning/deepdive/01_googleml/earthquakes\n",
    "```\n",
    "\n",
    "### Step 3\n",
    "Examine the ingest code using less:\n",
    "```\n",
    "less ingest.sh\n",
    "```\n",
    "The less command allows you to view the file (Press the spacebar to scroll down; the letter b to back up a page; the letter q to quit).\n",
    "\n",
    "The program ingest.sh downloads a dataset of earthquakes in the past 7 days from the US Geological Survey. Where is this file downloaded? To disk or to Cloud Storage? __________________________\n",
    "\n",
    "### Step 4\n",
    "Run the ingest code:\n",
    "```\n",
    "bash ingest.sh\n",
    "```\n",
    "\n",
    "### Step 5\n",
    "Verify that some data has been downloaded:\n",
    "```\n",
    "head earthquakes.csv\n",
    "```\n",
    "The head command shows you the first few lines of the file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform the data\n",
    "\n",
    "Duration is 3 min\n",
    "\n",
    "You will use a Python program to transform the raw data into a map of earthquake activity:\n",
    "\n",
    "### Step 1\n",
    "The transformation code is explained in detail in this notebook:\n",
    "\n",
    "https://github.com/GoogleCloudPlatform/datalab-samples/blob/master/basemap/earthquakes.ipynb\n",
    "\n",
    "Feel free to read the narrative to understand what the transformation code does. The notebook itself was written in Datalab, a GCP product that you will use later in this set of labs.\n",
    "\n",
    "### Step 2\n",
    "First, install the necessary Python packages on the Compute Engine instance:\n",
    "```\n",
    "bash install_missing.sh\n",
    "```\n",
    "\n",
    "### Step 3\n",
    "Then, run the transformation code:\n",
    "```\n",
    "./transform.py\n",
    "```\n",
    "\n",
    "### Step 4\n",
    "You will notice a new image file if you list the contents of the directory:\n",
    "```\n",
    "ls -l\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create bucket\n",
    "\n",
    "Duration is 2 min\n",
    "\n",
    "Create a bucket using the GCP console:\n",
    "\n",
    "### Step 1\n",
    "Browse to the GCP Console by visiting http://cloud.google.com and clicking on Go To Console\n",
    "\n",
    "### Step 2\n",
    "Click on the Navigation menu (3 bars) at the top-left and select Storage\n",
    "\n",
    "### Step 3\n",
    "Click on Create bucket.\n",
    "\n",
    "### Step 4\n",
    "Choose a globally unique bucket name (your project name is unique, so you could use that). You can leave it as Multi-Regional, or improve speed and reduce costs by making it Regional. Then, click Create.\n",
    "\n",
    "> Note: Please pick a region from the following: us-east1, us-central1, asia-east1, europe-west1. These are the regions that currently support Cloud ML Engine jobs. Please verify here since this list may have changed after this lab was last updated. For example, if you are in the US, you may choose us-east1 as your region.\n",
    "\n",
    "### Step 5\n",
    "Note down the name of your bucket: jxwbucket\n",
    "\n",
    "In this and future labs, you will insert this whenever the directions ask for `<YOUR-BUCKET>`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store data\n",
    "\n",
    "Duration is 1 min\n",
    "\n",
    "To store the original and transformed data in Cloud Storage\n",
    "\n",
    "### Step 1\n",
    "In the SSH window of the Compute Engine instance, type:\n",
    "```\n",
    "gsutil cp earthquakes.* gs://<YOUR-BUCKET>/earthquakes/\n",
    "```\n",
    "to copy the files to Cloud Storage\n",
    "\n",
    "### Step 2\n",
    "On the GCP console, click on your bucket name, and notice there are three new files present in the earthquakes folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Publish Cloud Storage files to web\n",
    "\n",
    "Duration is 2 min\n",
    "\n",
    "To publish Cloud Storage files to the web:\n",
    "\n",
    "### Step 1\n",
    "In the SSH window of the Compute Engine instance, type:\n",
    "```\n",
    "gsutil acl ch -u AllUsers:R gs://<YOUR-BUCKET>/earthquakes/*\n",
    "```\n",
    "\n",
    "### Step 2\n",
    "Click on the Public link corresponding to earthquakes.htm\n",
    "\n",
    "ce84dc744ff4c872.png\n",
    "\n",
    "### Step 3\n",
    "What is the URL of the published Cloud Storage file? How does it relate to your bucket name and content?\n",
    "\n",
    "https://storage.googleapis.com/jxwbucket/earthquakes/earthquakes.htm\n",
    "\n",
    "### Step 4\n",
    "What are some advantages of publishing to Cloud Storage? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up\n",
    "\n",
    "Duration is 2 min\n",
    "\n",
    "To delete the Compute Engine instance (since we won't need it any more):\n",
    "\n",
    "### Step 1\n",
    "On the GCP console, click the Navigation Menu (three horizontal bars) and select Compute Engine\n",
    "\n",
    "### Step 2\n",
    "Click on the checkbox corresponding to the instance that you created (the default name was instance-1)\n",
    "\n",
    "### Step 3\n",
    "Click on the Delete button in the top-right corner\n",
    "\n",
    "### Step 4\n",
    "Does deleting the instance have any impact on the files that you stored on Cloud Storage?\n",
    "_No, files stored on Cloud Storage still exist_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Duration is 1 min\n",
    "\n",
    "In this lab, you used Google Cloud Platform (GCP) as rented infrastructure. You can spin up a Compute Engine VM, install custom software on it, and run your processing jobs. However, using GCP in this way doesn't take advantage of the other benefits that Google Cloud Platform provides -- namely the ability to forget about infrastructure and work with your scientific computation problems simply as software that requires to be run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End your lab\n",
    "\n",
    "When you have completed your lab, click End Lab. Qwiklabs removes the resources you’ve used and cleans the account for you.\n",
    "\n",
    "You will be given an opportunity to rate the lab experience. Select the applicable number of stars, type a comment, and then click Submit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Connected, host fingerprint: ssh-rsa 0 22:72:9A:3E:41:11:A5:6B:FA:0F:A3:F6:B1:2D:4F:E9:73:C4:08:BE:89:EA:D8:A5:73:71:85:68:E1:66:DB:15\n",
    "Linux instance-1 4.9.0-8-amd64 #1 SMP Debian 4.9.130-2 (2018-10-27) x86_64\n",
    "\n",
    "The programs included with the Debian GNU/Linux system are free software;\n",
    "the exact distribution terms for each program are described in the\n",
    "individual files in /usr/share/doc/*/copyright.\n",
    "\n",
    "Debian GNU/Linux comes with ABSOLUTELY NO WARRANTY, to the extent\n",
    "permitted by applicable law.\n",
    "google2198582_student@instance-1:~$ cat /proc/cpuinfo \n",
    "processor       : 0\n",
    "vendor_id       : GenuineIntel\n",
    "cpu family      : 6\n",
    "model           : 45\n",
    "model name      : Intel(R) Xeon(R) CPU @ 2.60GHz\n",
    "stepping        : 7\n",
    "microcode       : 0x1\n",
    "cpu MHz         : 2600.000\n",
    "cache size      : 20480 KB\n",
    "physical id     : 0\n",
    "siblings        : 1\n",
    "core id         : 0\n",
    "cpu cores       : 1\n",
    "apicid          : 0\n",
    "initial apicid  : 0\n",
    "fpu             : yes\n",
    "fpu_exception   : yes\n",
    "cpuid level     : 13\n",
    "wp              : yes\n",
    "flags           : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc pni pclmulqdq ssse3 cx16 sse4_1 sse4_2 x2apic popcnt aes xsave avx hypervisor lahf_lm ssbd ibrs ibpb stibp kaiser tsc_adjust xsaveopt arat arch_capabilities\n",
    "bugs            : cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf\n",
    "bogomips        : 5200.00\n",
    "clflush size    : 64\n",
    "cache_alignment : 64\n",
    "address sizes   : 46 bits physical, 48 bits virtual\n",
    "power management:\n",
    "\n",
    "google2198582_student@instance-1:~$ git clone https://github.com/GoogleCloudPlatform/training-data-analyst\n",
    "Cloning into 'training-data-analyst'...\n",
    "remote: Enumerating objects: 88, done.\n",
    "remote: Counting objects: 100% (88/88), done.\n",
    "remote: Compressing objects: 100% (79/79), done.\n",
    "remote: Total 13777 (delta 50), reused 24 (delta 9), pack-reused 13689\n",
    "Receiving objects: 100% (13777/13777), 79.36 MiB | 34.04 MiB/s, done.\n",
    "Resolving deltas: 100% (8244/8244), done.\n",
    "google2198582_student@instance-1:~$ cd training-data-analyst/courses/machine_learning/deepdive/01_googleml/earthquakes\n",
    "google2198582_student@instance-1:~/training-data-analyst/courses/machine_learning/deepdive/01_googleml/earthquakes$ less ingest.sh \n",
    "google2198582_student@instance-1:~/training-data-analyst/courses/machine_learning/deepdive/01_googleml/earthquakes$ ls\n",
    "commands.sh      ingest.sh           scheduled\n",
    "earthquakes.htm  install_missing.sh  transform.py\n",
    "google2198582_student@instance-1:~/training-data-analyst/courses/machine_learning/deepdive/01_googleml/earthquakes$ bash ingest.sh \n",
    "--2019-01-26 03:48:23--  http://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/all_week.csv\n",
    "Resolving earthquake.usgs.gov (earthquake.usgs.gov)... 99.84.254.40, 99.84.254.42, 99.84.254.93, ...\n",
    "Connecting to earthquake.usgs.gov (earthquake.usgs.gov)|99.84.254.40|:80... connected.\n",
    "HTTP request sent, awaiting response... 301 Moved Permanently\n",
    "Location: https://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/all_week.csv [following]\n",
    "--2019-01-26 03:48:24--  https://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/all_week.csv\n",
    "Connecting to earthquake.usgs.gov (earthquake.usgs.gov)|99.84.254.40|:443... connected.\n",
    "HTTP request sent, awaiting response... 200 OK\n",
    "Length: unspecified [text/csv]\n",
    "Saving to: ‘earthquakes.csv’\n",
    "\n",
    "earthquakes.csv        [ <=>             ] 299.24K  --.-KB/s    in 0.03s   \n",
    "\n",
    "2019-01-26 03:48:24 (9.13 MB/s) - ‘earthquakes.csv’ saved [306419]\n",
    "\n",
    "google2198582_student@instance-1:~/training-data-analyst/courses/machine_learning/deepdive/01_googleml/earthquakes$ ls\n",
    "commands.sh      earthquakes.htm  install_missing.sh  transform.py\n",
    "earthquakes.csv  ingest.sh        scheduled\n",
    "google2198582_student@instance-1:~/training-data-analyst/courses/machine_learning/deepdive/01_googleml/earthquakes$ head earthquakes.csv \n",
    "time,latitude,longitude,depth,mag,magType,nst,gap,dmin,rms,net,id,updated,place,type,horizontalError,depthError,magError,magNst,status,locationSource,magSource\n",
    "2019-01-26T03:42:33.140Z,19.3481674,-155.4956665,7.4,1.74,md,45,47,0.07993,0.16,hv,hv70784846,2019-01-26T03:45:44.770Z,\"15km N of Pahala, Hawaii\",earthq\n",
    "uake,0.33,0.79,0.2,18,automatic,hv,hv\n",
    "2019-01-26T03:23:31.783Z,61.4887,-150.0462,47.5,1.9,ml,,,,0.4,ak,ak019171wbkq,2019-01-26T03:26:34.459Z,\"6km SW of Big Lake, Alaska\",earthquake,,0.8,,,automatic,ak,ak\n",
    "2019-01-26T03:15:59.030Z,36.6795006,-121.2963333,3.12,1.4,md,6,233,0.07007,0.03,nc,nc73136596,2019-01-26T03:31:02.163Z,\"12km S of Tres Pinos, CA\",earthquake,1.09,6.77,0.77,7,automatic,nc,nc\n",
    "2019-01-26T02:07:30.694Z,65.0562,-148.7665,22.4,1.1,ml,,,,0.36,ak,ak0191717a1p,2019-01-26T02:12:39.548Z,\"42km WNW of Ester, Alaska\",earthquake,,0.7,,,automatic,ak,ak\n",
    "2019-01-26T02:07:23.350Z,-10.8694,165.9495,52.31,5.7,mww,,56,11.149,0.99,us,us2000j92j,2019-01-26T02:26:26.402Z,\"21km SE of Lata, Solomon Islands\",earthquake,10.1,6,0.071,19,reviewed,us,us\n",
    "2019-01-26T02:01:39.990Z,33.5008333,-116.7981667,4.79,0.67,ml,27,63,0.01165,0.17,ci,ci38205487,2019-01-26T02:05:28.892Z,\"9km NE of Aguanga, CA\",earthquake,0.22,0.61,0.085,18,automatic,ci,ci\n",
    "2019-01-26T01:44:28.032Z,60.6037,-149.1678,19.3,2,ml,,,,0.39,ak,ak019170ty44,2019-01-26T01:56:45.787Z,\"32km SW of Whittier, Alaska\",earthquake,,0.3,,,automatic,ak,ak\n",
    "2019-01-26T01:39:24.100Z,37.6264992,-119.0413361,2.1,1.32,md,10,76,0.008541,0.03,nc,nc73136581,2019-01-26T02:55:03.528Z,\"6km WSW of Mammoth Lakes, CA\",earthquake,0.44,1.26,0.31,9,automatic,nc,nc\n",
    "2019-01-26T01:31:34.930Z,19.4026661,-155.2819977,0.35,2,ml,23,29,0.01072,0.06,hv,hv70784711,2019-01-26T01:37:17.360Z,\"5km SW of Volcano, Hawaii\",earthquake,0.15,0.19,0.25,13,automatic,hv,hv\n",
    "\n",
    "google2198582_student@instance-1:~/training-data-analyst/courses/machine_learning/deepdive/01_googleml/earthquakes$ ls -l\n",
    "total 632\n",
    "-rw-r--r-- 1 google2198582_student google2198582_student    637 Jan 26 03:45 commands.sh\n",
    "-rw-r--r-- 1 google2198582_student google2198582_student 306419 Jan 26 03:46 earthquakes.csv\n",
    "-rw-r--r-- 1 google2198582_student google2198582_student    751 Jan 26 03:45 earthquakesgoogle2198582_student@instance-1:~/training-data-analyst/courses/machine_learning/deepdive/01_googleml/earthquakes$ gsutil cp earthquakes.* gs://jxwbucket/earthquakes/    \n",
    "Copying file://earthquakes.csv [Content-Type=text/csv]...\n",
    "/ [0 files][    0.0 B/299.2 KiB]                         / [1 files][299.2 KiB/299.2 KiB]                         Copying file://earthquakes.htm [Content-Type=text/html]...\n",
    "- [1 files][299.2 KiB/300.0 KiB]                         - [2 files][300.0 KiB/300.0 KiB]                         Copying file://earthquakes.png [Content-Type=image/png]...\n",
    "- [2 files][300.0 KiB/606.2 KiB] \n",
    "google2198582_student@instance-1:~/training-data-analyst/courses/machine_learning/deepdive/01_googleml/earthquakes$ gsutil acl ch -u AllUsers:R gs://jxwbucket/earthquakes/*\n",
    "Updated ACL on gs://jxwbucket/earthquakes/earthquakes.csv\n",
    "Updated ACL on gs://jxwbucket/earthquakes/earthquakes.htm\n",
    "Updated ACL on gs://jxwbucket/earthquakes/earthquakes.png\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
