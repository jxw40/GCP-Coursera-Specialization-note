{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw Data to Features\n",
    "\n",
    "### What makes a good feature?\n",
    "1. Be related to the objective\n",
    "> Different problems in the same domain may need different features.\n",
    "\n",
    "2. Be known at prediction-time\n",
    "\n",
    "> Some data could be known immediately, and some other data is not known in real time.\n",
    "\n",
    "> You cannot train with current data and predict with stale data\n",
    "\n",
    "3. Be numeric with meaningful magnitude\n",
    "\n",
    "4. Have enough examples\n",
    "\n",
    "5. Bring human insight to problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representing Features\n",
    "\n",
    "### Representing Features\n",
    "Raw data are converted to numeric features in different ways\n",
    "\n",
    "Numeric values can be used as-is\n",
    "\n",
    "Categorical variables should be one-hot encoded\n",
    "\n",
    "Don't know the list of keys? Create a vocabulary\n",
    "![](images/Features/categorical.png)\n",
    "\n",
    "Don't mix magic numbers with data. Have missing data, add an extra column to state whether or not you observed the value or not.\n",
    "\n",
    "### ML vs Statistics\n",
    "\n",
    "ML = lots of data, keep outliers and build models for them\n",
    "\n",
    "Statistics = \"l've got all the data I'll ever get\", throw away outliers\n",
    "\n",
    "Exact floats are not meaningful. Discretize floating point values into bins\n",
    "\n",
    "Crazy outliers will hurt trainablity. Ideally, features should have similar range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing and Feature Creation\n",
    "\n",
    "![](images/Features/preprocessing.png)\n",
    "![](images/Features/feature_creation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apache Beam and Cloud Dataflow\n",
    "\n",
    "Beam is a way to write elastic data processing pipelines\n",
    "\n",
    "To implement a data processing pipeline, you write your code using the Apache Beam APIs, and then deploy the code to Cloud Dataflow.\n",
    "![](images/Beam_DataFlow/pipeline.png)\n",
    "\n",
    "The code is the same between real-time and batch\n",
    "![](images/Beam_DataFlow/dataflow.png)\n",
    "![](images/Beam_DataFlow/pipeline2.png)\n",
    "![](images/Beam_DataFlow/PCollection.png)\n",
    "![](images/Beam_DataFlow/ingest.png)\n",
    "![](images/Beam_DataFlow/write.png)\n",
    "![](images/Beam_DataFlow/execute.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pipelines that Scale\n",
    "\n",
    "MapReduce approach splits Big Data so that each compute node pprocessed data local to it\n",
    "\n",
    "Apache Beam ParDo class\n",
    "![](images/Beam_DataFlow/ParDo.png)\n",
    "\n",
    "![](images/Beam_DataFlow/map_flatmap.png)\n",
    "![](images/Beam_DataFlow/groupby.png)\n",
    "![](images/Beam_DataFlow/Combine_PerKey.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Preprocessing with Cloud Dataprep\n",
    "![](images/CloudDataprep/two_approaches_preprocessing.png)\n",
    "\n",
    "**First approach**\n",
    "\n",
    "The default Datalab environment is running on a single virtual server with a limited amount of memory. In some case, it will be impractical or too expensive to plot and analyze all of them using just a single datalab environment. \n",
    "**Best to aggregate in BigQuery and plot in Datalab.\n",
    "Write DataFlow code to do any transformations.**\n",
    "\n",
    "**Second approach**\n",
    "\n",
    "using Cloud Dataprep for exploring and preprocessing data\n",
    "![](images/CloudDataprep/CloudDataprep.png)\n",
    "![](images/CloudDataprep/CloudDataprep_wrangles.png)\n",
    "![](images/CloudDataprep/wranglers_transformation.png)\n",
    "![](images/CloudDataprep/monitor_Dataprep.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducing Feature Crosses\n",
    "![](images/FeatureCrosses/feature_crosses.png)\n",
    "\n",
    "### Memorization cs Generalization\n",
    "\n",
    "Feature crosses memorize\n",
    "\n",
    "Goal of ML is generalization\n",
    "\n",
    "Memorization works when you have lots of data\n",
    "\n",
    "Feature crosses are powerful\n",
    "\n",
    "**Feature Crosses bring a lot of power to linear models**\n",
    "\n",
    "Feature crosses + massive data is an efficient way for learning highly complex spaces\n",
    "\n",
    "Feature crosses allow a linear model to memorize large datasets\n",
    "\n",
    "Optimizing linear models is a convex problem\n",
    "\n",
    "Before TensorFlow, Google used massive scale learners\n",
    "\n",
    "Feature crosses, as a preprocessor, make neural networks converge a lot quicker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataset=xor\n",
    "![](images/FeatureCrosses/xor.png)\n",
    "\n",
    "dataset=circle\n",
    "![](images/FeatureCrosses/circle.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which of these is a **good feature cross**?\n",
    "\n",
    "Different cities in California have markedly different housing prices. Suppose you must create a model to predict housing prices. Which of the following sets of features or feature crosses could learn city-specific relationships between house characteristic and housing price?\n",
    "\n",
    "\n",
    "Three separate binned features: [binned latitude], [binned longitude], [binned roomsPerPerson]\n",
    "\n",
    "\n",
    "Two feature crosses: [binned latitude X binned roomsPerPerson] and [binned longitude X binned roomsPerPerson]\n",
    "\n",
    "\n",
    "One feature cross: [latitude X longitude X roomsPerPerson]\n",
    "\n",
    "\n",
    "**One feature cross: [binned latitude X binned longitude X binned roomsPerPerson]**\n",
    "\n",
    "> 正确 \n",
    "Yes. Crossing binned latitude with binned longitude enables the model to learn city-specific effects of roomsPerPerson. Binning prevents a change in latitude producing the same result as a change in longitude. Depending on the granularity of the bins, this feature cross could learn city-specific or neighborhood-specific or even block-specific effects.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lab Solution: Too Much of a Good thing\n",
    "\n",
    "http://goo.gl/ofiHCT\n",
    "\n",
    "feature cross can cause overfit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Feature Crosses\n",
    "\n",
    "![](images/FeatureCrosses/hash_bucket.png)\n",
    "\n",
    "### Embedding Feature Crosses\n",
    "\n",
    "The model learns how to embed the feature cross in lower-dimensional space\n",
    "![](images/FeatureCrosses/embedding.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Where to Do Feature Engineering\n",
    "\n",
    "![](images/FeatureCrosses/three_places.png)\n",
    "![](images/FeatureCrosses/preprocessing_feature_column.png)\n",
    "![](images/FeatureCrosses/preprocessing_tf.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Creation in TensorFlow\n",
    "![](images/FeatureCrosses/create_feature_tf.png)\n",
    "![](images/FeatureCrosses/call_all_input.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Creation in DataFlow\n",
    "![](images/FeatureCrosses/add_feature_dataflow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow Transform\n",
    "![](images/Transform/three_places_pros_cons.png)\n",
    "TensorFlow is good for on-demand, on-the-fly processing\n",
    "![](images/Transform/hybrid.png)\n",
    "![](images/Transform/two_PTransforms.png)\n",
    "![](images/Transform/two_phases.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Analyze phase\n",
    "![](images/Transform/analyze_phase1.png)\n",
    "![](images/Transform/analyze_phase2.png)\n",
    "![](images/Transform/analyze_phase3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform phase\n",
    "![](images/Transform/transform_phase_preprocessing1.png)\n",
    "![](images/Transform/transform_phase_preprocessing2.png)\n",
    "Analyze and Tranform happens on the training dataset\n",
    "![](images/Transform/transform_eval.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supporting serving\n",
    "\n",
    "Fo training and evaluation, we created preprocessed features using Beam\n",
    "![](images/Transform/serving.png)\n",
    "![](images/Transform/input_function.png)\n",
    "![](images/Transform/serving_input.png)\n",
    "The model graph includes the preprocessing code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
