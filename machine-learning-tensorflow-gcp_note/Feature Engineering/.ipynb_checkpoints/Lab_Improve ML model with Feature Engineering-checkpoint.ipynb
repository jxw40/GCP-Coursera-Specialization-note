{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improve ML model with Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "Duration is 1 min\n",
    "\n",
    "This lab is part of a lab series, where you go from exploring a taxicab dataset to training and deploying a high-accuracy distributed model with Cloud ML Engine.\n",
    "\n",
    "### What you learn\n",
    "In this lab, you will improve the ML model using feature engineering. In the process, you will learn how to:\n",
    "\n",
    "* Work with feature columns\n",
    "* Add feature crosses in TensorFlow\n",
    "* Read data from BigQuery\n",
    "* Create datasets using Dataflow\n",
    "* Use a wide-and-deep model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launch Cloud Datalab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clone course repo within your Datalab instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "Duration is 15 min\n",
    "\n",
    "### Step 1\n",
    "In Cloud Datalab, click on the Home icon, and then navigate to datalab/notebooks/training-data-analyst/courses/machine_learning/deepdive/04_features/taxifeateng/ and open feateng.ipynb.\n",
    "\n",
    "> Note: If the cloud shell used for running the datalab command is closed or interrupted, the connection to your Cloud Datalab VM will terminate. If that happens, you may be able to reconnect using the command â€˜datalab connect mydatalabvm' in your new Cloud Shell. Once connected, try the above step again.\n",
    "\n",
    "### Step 2\n",
    "In Datalab, click on Clear, then click on Clear | All Cells. Now read the narrative and execute each cell in turn.\n",
    "\n",
    "The solution video will demo notebooks that contain hyper-parameter tuning and training on 500 million rows of data. The changes to the model are minor -- essentially just command-line parameters, but the impact on model accuracy is huge:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
