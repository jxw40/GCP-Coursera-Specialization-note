{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendation Systems Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "Recommendation Systems...\n",
    "* Help users find related content\n",
    "* Help users explore new items\n",
    "* Improve user decision making\n",
    "\n",
    "For producers, recommendation systems...\n",
    "* Increase user engagement\n",
    "* Learn more about customers\n",
    "* Change user behavior\n",
    "\n",
    "Recommendation Systems provide a way to **model people's preferences**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content-Based or Collaborative\n",
    "\n",
    "**Content-based filtering** uses item features to recommend new items similar to what the user has liked in the past.\n",
    "\n",
    "**Collaborative Filtering** uses similarities between users and items simutaneously to determine recommendations.\n",
    "\n",
    "**Knowledge-based** recommender systems use explicit knowledge about the user, items, and recommendation criteria.\n",
    "\n",
    "**Deep neural networks**\n",
    "![](images/dnn.png)\n",
    "\n",
    "At inference time, we can apply this model to rate previously unseen videos and recommend to the user the video with the highest score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommendation System Pitfalls\n",
    "\n",
    "The user space and product space are **sparse** and **skewed**\n",
    "\n",
    "The user space and product space are sparse:\n",
    "* Most items are rated by fewer users.\n",
    "* Most users rate only a small fraction of items.\n",
    "\n",
    "The user space and product space are skewed:\n",
    "* Some properties are very popular\n",
    "* Some users are very profilic.\n",
    "\n",
    "The **cold start problem** occurs when there aren't enough interactions for users or items.\n",
    "\n",
    "Explicit user feedback is often rare or unobservable\n",
    "\n",
    "**Implicit feedback** is much more readily available\n",
    "\n",
    "![](images/implicit_feedback.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Simple Vector-Based Model\n",
    "\n",
    "### Content-Based Recommendation Systems\n",
    "\n",
    "**Content-based filtering** uses item features to recommend new items similar to what the user has liked in the past.\n",
    "\n",
    "### Similarity Measures\n",
    "\n",
    "An embedding is a map from our collection of items to some finite dimensional vector space.\n",
    "\n",
    "A **similarity measure** is a metric for items in an embedding space.\n",
    "\n",
    "dot product\n",
    "\n",
    "cosine similarity\n",
    "\n",
    "### Building a User Vector\n",
    "\n",
    "![](images/user_vector.png)\n",
    "![](images/user_vector2.png)\n",
    "\n",
    "### Making Recommendations Using a User Vector\n",
    "\n",
    "![](images/user_vector_recommend.png)\n",
    "![](images/user_vector_recommend2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Recommendations for Many Users\n",
    "\n",
    "![](images/matrix.png)\n",
    "![](images/create_matrix.png)\n",
    "![](images/many_user1.png)\n",
    "![](images/many_user_code1.png)\n",
    "(users, movies, features)\n",
    "![](images/many_user2.png)\n",
    "![](images/many_user_code2.png)\n",
    "![](images/many_user3.png)\n",
    "![](images/many_user_code3.png)\n",
    "![](images/many_user4.png)\n",
    "![](images/many_user5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Building a Content-Based Recommendation System with a Neural Network\n",
    "### Using Neural Networks for Content-Based Recommendation Systems\n",
    "![](images/kurier.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALS, a Matrix Factorization Algorithm For Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Types of User Feedback Data\n",
    "\n",
    "Content-based recommendation use similarities between items in an embedding space\n",
    "\n",
    "What if we don't know the best factors to compare with?\n",
    "\n",
    "Collaborative filtering learns latent factors and can explore outside user's personal bubble\n",
    "\n",
    "Collaborative filtering recommendations use similarities between **items and user simultaneously** in an embedding space\n",
    "\n",
    "Start from a user-interaction matrix where rows are users and items are columns\n",
    "* Sometimes these ratings are explicit\n",
    "* Most often these rating are implicit\n",
    "\n",
    "If we were creating a YouTube video recommender system where we had “like” and “dislike” data and also the duration a video was watched, which feedback would be considered explicit and which would be considered implicit?\n",
    "\n",
    "Explicit, Implicit\n",
    "\n",
    "> 正确 \n",
    "Correct! Like/dislike is explicit because it speaks to how the user feels about video and watch duration is implicit because it doesn't directly speak to how a user feels about a video.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding Users and Items\n",
    "\n",
    "We can organize items by similarity in two dimensions\n",
    "\n",
    "Simply take the dot product between users and items in embedding space\n",
    "![](images/based_on_user.png)\n",
    "![](images/based_on_item.png)\n",
    "\n",
    "Each user and items is a d-dimensional point within an embedding space.\n",
    "\n",
    "Embeddings can be **learned from data**.\n",
    "\n",
    "We're compressing the data to find the best generalities to rely on, called **latent factors**.\n",
    "\n",
    "![](images/factorization.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Factorization Approaches\n",
    "\n",
    "Collaborative filtering is usually carried out using matrix factorization\n",
    "* Factorize user-interactions matrix into user-factors and item-factors.\n",
    "* Given user ID, multiply by item-factors to get predicted rating for all items.\n",
    "* Return top k rated items for this user.\n",
    "\n",
    "Alternating least squares(ALS)\n",
    "\n",
    "Unobserved pairs\n",
    "![](images/SVD.png)\n",
    "![](images/ALS.png)\n",
    "![](images/WALS.png)\n",
    "\n",
    "There are many ways to handle unobserved user-interaction matrix pairs. _______ explicitly sets all missing values to zero. _______ simply ignores missing values. _____ uses weights instead of zeros that can be thought of as representing _____.\n",
    "\n",
    "**SVD, ALS, WALS, low confidence**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The ALS Algorithm\n",
    "\n",
    "The WALS Estimator in TensorFlow does not need any labels; it just needs the ratings matrix organized into rows and columns\n",
    "\n",
    "![](images/WALS_feeding_tf.png)\n",
    "![](images/WALS_weighted.png)\n",
    "![](images/ALS_algorithm.png)\n",
    "![](images/ALS_solving_quiz.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Input Data for ALS\n",
    "\n",
    "#### Getting data to the ALS algorithm\n",
    "\n",
    "Feed the ALS algorithm whole rows(or columns) at a time, but because knowing which stage it's in is difficult, feed both!\n",
    "![](images/iterative_algorithm.png)\n",
    "\n",
    "![](images/map_id.png)\n",
    "Save the mapping to persistent storage because you'll need to map input values to the mapped values!\n",
    "\n",
    "![](images/precomputing_Gramian.png)\n",
    "\n",
    "![](images/WALS_map_quiz.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing ALS in TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Sparse Tensors For Efficient WALS Input\n",
    "\n",
    "Because WALS requires whole rows or columns, the data has to be preprocessed to provide SparseTensors of rows/columns\n",
    "\n",
    "![](images/preprocess_SparseTensors.png)\n",
    "![](images/sparse_merge.png)\n",
    "\n",
    "If we want to recommend items for a user, when we are writing out to the TF Record file:\n",
    "\n",
    "Our key train feature should be _________.\n",
    "\n",
    "Our indices train feature should be _________.\n",
    "\n",
    "Our values train feature should be _________.\n",
    "\n",
    "**E. user, itemID, rating**\n",
    "\n",
    "A. item, userID, rating  --> recommend users for an item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiating a WALS Estimator: From Input to Estimator\n",
    "\n",
    "![](images/WALS_estimator.png)\n",
    "![](images/input_fn.png)\n",
    "\n",
    "The WALS MF estimator takes the INPUT_ROWS and INPUT_COLS as features. If we have our items_for_user and users_for_item TF Records, which filename and vocab_size should we use for each of these features, respectively?\n",
    "\n",
    "**items_for_user, nitems, users_for_item, nusers**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiating a WAL Estimator: Decoding TFRecords\n",
    "\n",
    "![](images/decode_SparseTensor.png)\n",
    "\n",
    "In our decode_example function, we use VarLenFeature indices and values because of ______, we perform a sparse_merge because of ______, and we concatenate the key because of ______.\n",
    "\n",
    "**having many ratings per row/col, needing SparseTensors, batching**\n",
    "\n",
    "we concatenate the key to the indices tensor because batching overwrites the first dimension of the indices with the batch index, so we use this trick and remap keys function later to correct it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiating a WALS Estimator: Recovering Keys\n",
    "\n",
    "Remap key to SparseTensor to fix re-indexing after batching\n",
    "\n",
    "![](images/remap.png)\n",
    "![](images/remap2.png)\n",
    "![](images/remap3.png)\n",
    "![](images/remap4.png)\n",
    "![](images/remap5.png)\n",
    "![](images/remap6.png)\n",
    "\n",
    "![](images/remap_keys_quiz.png)\n",
    "![](images/after_remap_keys.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiating a WALS Estimator: Training and Prediction\n",
    "\n",
    "flip recommendations from users to items\n",
    "![](images/project_row.png)\n",
    "\n",
    "![](images/train_and_evaluate.png)\n",
    "\n",
    "![](images/finding_top_k.png)\n",
    "![](images/top_k_batch_predict.png)\n",
    "\n",
    "We saw how to recommend the top K items for users, but what if we wanted to instead **recommend the top K users for items**? What would be the correct change in our batch prediction function?\n",
    "```\n",
    "topk = tf.squeeze(tf.map_fn(lambda ____: \n",
    "              find_top_k(____, _____,args['topk']), _____,\n",
    "              dtype=tf.int64))\n",
    "```\n",
    "\n",
    "**item, item, user_factors, item_factors**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issues with Collaborative Filtering\n",
    "\n",
    "Our batch predictions were problematic\n",
    "\n",
    "What we really need are visitorId and contentId in our prediction files, not the enumerated userId and itemId\n",
    "\n",
    "We should use TensorFlow-Transform to:\n",
    "1. Create the group-by dataset.\n",
    "2. Create the vocabulary of visitorId->userId\n",
    "3. Use the vocabulary when doing predictions\n",
    "\n",
    "![](images/transform_assets.png)\n",
    "![](images/convert_back.png)\n",
    "\n",
    "We want a scalable way to generate predictions that directly tie back to the original data and not just enumerated indices. We should use TensorFlow-Transform to first create ____________, then create ____________, and lastly create ____________.\n",
    "\n",
    "**group-by datasets, vocabularies, predictions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Productionized WALS Demo\n",
    "\n",
    "https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/courses/machine_learning/deepdive/10_recommend/wals_tft.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cold Starts\n",
    "\n",
    "#### Collaborative filtering seems powerful... but it's not without its drawbacks.\n",
    "Pros:\n",
    "* No domain knowledge\n",
    "* Serendipity\n",
    "* Great starting point\n",
    "\n",
    "Cons:\n",
    "* Fresh items/users?\n",
    "* Context features?\n",
    "\n",
    "#### WALS is thus a way to get user and item embeddings\n",
    "* These embeddings are created solely from user behavior.\n",
    "* Would be nice to also use knowledge about the item(content-based) and knowledge about the user(knowledge-based).\n",
    "* How would we combine multiple predictors?\n",
    "\n",
    "![](images/how_to_hybrid.png)\n",
    "![](images/cold_start_strategies_quiz.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
