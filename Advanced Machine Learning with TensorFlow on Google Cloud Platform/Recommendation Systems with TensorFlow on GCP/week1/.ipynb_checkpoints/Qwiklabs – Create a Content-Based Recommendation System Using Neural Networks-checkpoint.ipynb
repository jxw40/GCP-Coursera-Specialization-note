{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [ML on GCP C10] Content-Based Filtering using Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "This lab shows you how to do content-based filtering using DNNs in TensorFlow.\n",
    "\n",
    "### Objectives\n",
    "In this lab, you learn to perform the following tasks:\n",
    "\n",
    "* Build the feature columns for a DNN model using `tf.feature_column`\n",
    "\n",
    "* Create custom evaluation metrics and add them to TensorBoard\n",
    "\n",
    "* Train a DNN model for content-based recommendations and perform predictions with that model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "In this lab, you'll be providing building a DNN to make content-based recommendations. Content based filtering uses features of the items and users to generate recommendations. In this example, we'll be making recommendations for users on the Kurier.at news site. To do this, we'll be using features based on the news text, title, author, and recency of the article."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open a Datalab notebook\n",
    "1. In the Datalab browser, navigate to datalab > notebooks > training-data-analyst > courses > machine_learning > deepdive > 10_recommend > labs > content_based_preproc.ipynb.\n",
    "\n",
    "2. Read the commentary, click Clear | Clear all Cells, then run the Python snippets (Use Shift+Enter to run each piece of code) in the cell, step by step.\n",
    "\n",
    "3. In the Datalab browser, navigate to datalab > notebooks > training-data-analyst > courses > machine_learning > deepdive > 10_recommend > labs > content_based_using_neural_networks.ipynb.\n",
    "\n",
    "4. Read the commentary, click Clear | Clear all Cells, then run the Python snippets (Use Shift+Enter to run each piece of code) in the cell, step by step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](hits.customDimensions.index.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299931241\n",
      "299913879\n",
      "299922662\n",
      "299826775\n",
      "299930679\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "awk -F \"\\\"*,\\\"*\" '{print $7}' first_5.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
