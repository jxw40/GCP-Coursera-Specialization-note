{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [ML on GCP C10] Collaborative Filtering on Google Analytics data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "This lab shows you how to do collaborative filtering with Weighted Alternating Least Squares (WALS) matrix refactorization approach.\n",
    "\n",
    "### Objectives\n",
    "In this lab, you learn to perform the following tasks:\n",
    "\n",
    "* Prepare the user-item matrix for use with WALS\n",
    "\n",
    "* Train a WALSMatrixFactorization within TensorFlow locally and on Cloud ML Engine\n",
    "\n",
    "* Visualize the embedding vectors with principal components analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "In this lab, you'll be providing article recommendations for users based on the Kurier.at data. Recall that collaborative filtering doesn't need to know anything about the content. We are only interested in the user-item matrix which defines their relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open a Datalab notebook\n",
    "In Cloud Datalab, click on the Home icon, and then navigate to datalab > notebook > training-data-analyst > courses > machine_learning > deepdive > 10_recommend > labs > wals.ipynb.\n",
    "\n",
    "Read the commentary, click Clear | Clear all Cells, then run the Python snippets (Use Shift+Enter to run each piece of code) in the cell, step by step.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "data/items.csv  item_mapping\n",
    "contentId -> itemId [0,1,2...]\n",
    "\n",
    "data/users.csv  user_mapping\n",
    "visitorId -> userId [0,1,2...]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`def remap_keys(sparse_tensor):`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sparse_tensor = tf.SparseTensor(indices=[[0,2],[0,0],[1,0],[1,1],[1,1]], values=[1.5, 0., 3.5, 2.5, 0.], dense_shape=[ 2, 5668])\n",
    "sparse_tensor = tf.SparseTensor(indices=[[0,0],[0,1],[0,2],[0,2],[1,2],[1,3]], values=[2.5,1.5,4.5,0.,3.5,0.], dense_shape=[ 2, 5668])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseTensorValue(indices=array([[0, 0],\n",
      "       [0, 1],\n",
      "       [0, 2],\n",
      "       [0, 2],\n",
      "       [1, 2],\n",
      "       [1, 3]]), values=array([2.5, 1.5, 4.5, 0. , 3.5, 0. ], dtype=float32), dense_shape=array([   2, 5668]))\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    print(sparse_tensor.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 1]\n",
      "2\n",
      "[3 4]\n"
     ]
    }
   ],
   "source": [
    "bad_indices = sparse_tensor.indices\n",
    "# Current values of our SparseTensor that we need to fix\n",
    "bad_values = sparse_tensor.values \n",
    "\n",
    "# Group by the batch_indices and get the count for each  \n",
    "size = tf.segment_sum(data = tf.ones_like(bad_indices[:,0], dtype = tf.int64), segment_ids = bad_indices[:,0]) - 1\n",
    "# The number of batch_indices (this should be batch_size unless it is a partially full batch)\n",
    "length = tf.shape(size, out_type = tf.int64)[0]\n",
    "# Finds the cumulative sum which we can use for indexing later\n",
    "cum = tf.cumsum(size)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(size.eval())\n",
    "    print(length.eval())\n",
    "    print(cum.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "[3 5]\n"
     ]
    }
   ],
   "source": [
    "# The offsets between each example in the batch due to our concatentation of the keys in the decode_example method\n",
    "length_range = tf.range(start = 0, limit = length, delta = 1, dtype = tf.int64)\n",
    "# Indices of the SparseTensor's indices member of the rows we added by the concatentation of our keys in the decode_example method\n",
    "cum_range = cum + length_range\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(length_range.eval())\n",
    "    print(cum_range.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3]\n",
      "[0 1 2 3 4 5]\n"
     ]
    }
   ],
   "source": [
    "# The keys that we have extracted back out of our concatentated SparseTensor\n",
    "gathered_indices = tf.squeeze(tf.gather(bad_indices, cum_range)[:,1])\n",
    "\n",
    "# The enumerated row indices of the SparseTensor's indices member\n",
    "sparse_indices_range = tf.range(tf.shape(bad_indices, out_type = tf.int64)[0], dtype = tf.int64)\n",
    "    \n",
    "# We want to find here the row indices of the SparseTensor's indices member that are of our actual data and not the concatentated rows\n",
    "# So we want to find the intersection of the two sets and then take the opposite of that\n",
    "x = sparse_indices_range\n",
    "s = cum_range\n",
    "    \n",
    "with tf.Session() as sess:\n",
    "    print(gathered_indices.eval())\n",
    "    print(sparse_indices_range.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2]\n",
      "[[0 0]\n",
      " [1 1]\n",
      " [2 2]\n",
      " [3 3]\n",
      " [4 4]\n",
      " [5 5]]\n",
      "[ True  True  True False  True False]\n"
     ]
    }
   ],
   "source": [
    "# Number of multiples we are going to tile x, which is our sparse_indices_range\n",
    "tile_multiples = tf.concat([tf.ones(tf.shape(tf.shape(x)), dtype=tf.int64), tf.shape(s, out_type = tf.int64)], axis = 0)\n",
    "# Expands x, our sparse_indices_range, into a rank 2 tensor and then multiplies the rows by 1 (no copying) and the columns by the number of examples in the batch\n",
    "x_tile = tf.tile(tf.expand_dims(x, -1), tile_multiples)\n",
    "# Essentially a vectorized logical or, that we then negate\n",
    "x_not_in_s = ~tf.reduce_any(tf.equal(x_tile, s), -1)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(tile_multiples.eval())\n",
    "    print(x_tile.eval())\n",
    "    print(x_not_in_s.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0]\n",
      " [0 1]\n",
      " [0 2]\n",
      " [1 2]]\n",
      "[2.5 1.5 4.5 3.5]\n",
      "[2 2 2]\n"
     ]
    }
   ],
   "source": [
    "# The SparseTensor's indices that are our actual data by using the boolean_mask we just made above applied to the entire indices member of our SparseTensor\n",
    "selected_indices = tf.boolean_mask(tensor = bad_indices, mask = x_not_in_s, axis = 0)\n",
    "# Apply the same boolean_mask to the entire values member of our SparseTensor to get the actual values data\n",
    "selected_values = tf.boolean_mask(tensor = bad_values, mask = x_not_in_s, axis = 0)\n",
    "\n",
    "# Need to replace the first column of our selected_indices with keys, so we first need to tile our gathered_indices\n",
    "tiling = tf.tile(input = tf.expand_dims(gathered_indices[0], -1), multiples = tf.expand_dims(size[0] , -1))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(selected_indices.eval())\n",
    "    print(selected_values.eval())\n",
    "    print(tiling.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 3]\n",
      "[[2 0]\n",
      " [2 1]\n",
      " [2 2]\n",
      " [3 2]]\n"
     ]
    }
   ],
   "source": [
    "# We have to repeatedly apply the tiling to each example in the batch\n",
    "# Since it is jagged we cannot use tf.map_fn due to the stacking of the TensorArray, so we have to create our own custom version\n",
    "def loop_body(i, tensor_grow):\n",
    "  return i + 1, tf.concat(values = [tensor_grow, tf.tile(input = tf.expand_dims(gathered_indices[i], -1), multiples = tf.expand_dims(size[i] , -1))], axis = 0)\n",
    "\n",
    "_, result = tf.while_loop(lambda i, tensor_grow: i < length, loop_body, [tf.constant(1, dtype = tf.int64), tiling])\n",
    "\n",
    "# Concatenate tiled keys with the 2nd column of selected_indices\n",
    "selected_indices_fixed = tf.concat([tf.expand_dims(result, -1), tf.expand_dims(selected_indices[:, 1], -1)], axis = 1)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(result.eval())\n",
    "    print(selected_indices_fixed.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseTensorValue(indices=array([[2, 0],\n",
      "       [2, 1],\n",
      "       [2, 2],\n",
      "       [3, 2]]), values=array([2.5, 1.5, 4.5, 3.5], dtype=float32), dense_shape=array([   2, 5668]))\n"
     ]
    }
   ],
   "source": [
    "# Combine everything together back into a SparseTensor\n",
    "remapped_sparse_tensor = tf.SparseTensor(indices = selected_indices_fixed, values = selected_values, dense_shape = sparse_tensor.dense_shape)\n",
    "  \n",
    "with tf.Session() as sess:\n",
    "    print(remapped_sparse_tensor.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
