{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [ML on GCP C9] Text Classification using TensorFlow/Keras on Cloud ML Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "Duration is 1 min\n",
    "\n",
    "In this lab, you will define a text classification model to look at the titles of articles and figure out whether the article came from the New York Times, TechCrunch or GitHub.\n",
    "\n",
    "### What you learn\n",
    "In this lab, you will learn how to:\n",
    "\n",
    "* Creating datasets for Machine Learning using BigQuery\n",
    "\n",
    "* Creating a text classification model using the Estimator API with a Keras model\n",
    "\n",
    "* Training on Cloud ML Engine\n",
    "\n",
    "* Deploying the model\n",
    "\n",
    "* Predicting with model\n",
    "\n",
    "* Rerun with pre-trained embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Sequence Model for Text Classification\n",
    "Duration is 15 min\n",
    "\n",
    "The model code is packaged as a separate python module. You will first complete the model code and then switch to the notebook to set some parameters and run the training job.\n",
    "\n",
    "### Step 1\n",
    "\n",
    "In Cloud Datalab, click on the Home icon, and then navigate to datalab > notebooks > training-data-analyst > courses > machine_learning > deepdive > 09_sequence > labs and open text_classification.ipynb.\n",
    "\n",
    "> Note: If the cloud shell used for running the datalab command is closed or interrupted, the connection to your Cloud Datalab VM will terminate. If that happens, you may be able to reconnect using the command â€˜datalab connect mydatalabvm' in your new Cloud Shell. Once connected, try the above step again.\n",
    "\n",
    "### Step 2\n",
    "\n",
    "Read through the assignment steps required in the first notebook cell and complete them in your notebook.\n",
    "\n",
    "Be sure to complete the #TODOs in the companion model.py notebook found in datalab > notebooks > training-data-analyst > courses > machine_learning > deepdive > 09_sequence > labs > txtclsmodel > trainer > model.py.\n",
    "\n",
    "If you need more help, you may take a look at the complete solution by navigating datalab > notebooks > training-data-analyst > courses > machine_learning > deepdive > 09_sequence > txtclsmodel > trainer > model.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mobile', 'nytimes', 'com']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "url = 'http://mobile.nytimes.com/dasd'\n",
    "\n",
    "matchObj = re.match('.*://(.[^/]+)/', url)\n",
    "print(matchObj.group(1).split('.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Job Details\n",
    "\n",
    "2019-02-11 16:13:25.787 HKT\n",
    "master-replica-0\n",
    "Saving dict for global step 2819: acc = 0.8155359, global_step = 2819, loss = 0.4472113"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
