{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling sequences with DNNs\n",
    "\n",
    "Linear models remain good tools\n",
    "\n",
    "Sometimes, it's important that models capture aspects of the real world\n",
    "\n",
    "Regularization can restrain for sparsity\n",
    "\n",
    "What of **recency** is important?\n",
    "\n",
    "Constrain the weights for better performance. \n",
    "\n",
    "* Use exponential smoothing\n",
    "\n",
    "* Autoregressive ARMA models use moving averages\n",
    "\n",
    "$$ X_t = c + \\sum_{i=1}^{p}{\\varphi_i X_{t-1} + \\epsilon_t} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling sequences with CNNs\n",
    "\n",
    "What do images and sequences have in common?\n",
    "\n",
    "Locality is important for images and sequences\n",
    "\n",
    "Convolutional filters are pattern matchers\n",
    "\n",
    "![](convolution.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The variable-length problem\n",
    "\n",
    "Handling variable length inputs and outputs\n",
    "\n",
    "1. Cutting and padding\n",
    "2. Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introducing Recurrent Neural Networks\n",
    "\n",
    "RNNs scan their input just like CNNs\n",
    "\n",
    "Two key ideas for RNNs\n",
    "1. RNNs learn a compact hidden state that represents the past\n",
    "2. The input to an RNN is a concatenation of the original, stateless input and the hidden state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How RNNs represent the past\n",
    "\n",
    "RNNs can create power representations of the past\n",
    "\n",
    "How RNNs Remember the Past\n",
    "1. Recurrent conection\n",
    "2. Clever optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTMs, GRUs, and RNNs in TensorFlow\n",
    "### RNNs in TensorFlow\n",
    "\n",
    "![](RNN_tf.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep RNNs\n",
    "\n",
    "![](deep_RNNs.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving our Loss Function\n",
    "### Working with Real Data\n",
    "\n",
    "Splitting up sequences\n",
    "\n",
    "Sequence Length\n",
    "\n",
    "Predicting multiple time steps ahead\n",
    "\n",
    "Other consideration\n",
    "* Resampling data\n",
    "* One model vs. multiple models\n",
    "* Incorporating non-sequential data\n",
    "\n",
    "![](non-sequential.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
