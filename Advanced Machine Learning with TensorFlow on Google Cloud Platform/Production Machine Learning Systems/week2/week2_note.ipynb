{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Designing Adaptable ML systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adapting to Data\n",
    "### Adapting to Data\n",
    "\n",
    "Decoupled upstream data producers\n",
    "\n",
    "Underutilized data dependencies\n",
    "\n",
    "### Changing Distributions\n",
    "\n",
    "Distributions change\n",
    "* Monitor descriptive statistics for your inputs and outputs\n",
    "* Monitor your residuals as a function of your inputs\n",
    "* Use custom weights in your loss function to emphasize data recency\n",
    "* Use dynamic training architecture and regularly retrain your model\n",
    "\n",
    "### Right and Wrong Decisions\n",
    "\n",
    "### System Failure\n",
    "\n",
    "System Fail\n",
    "\n",
    "Feedback Loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mitigating Training-Serving Skew through Design\n",
    "\n",
    "Training/Serving Skew\n",
    "1. A discrepancy between how you handle data in the training and serving pipelines\n",
    "2. A change in the data between when you train and when you serve\n",
    "3. A feedback loop between your model and your algorithm\n",
    "\n",
    "How Code Can Create Training/Serving Skew\n",
    "* Different library versions that are functional equivalent but optimized differently\n",
    "* Different library versions that are not functional equivalent\n",
    "* Re-implemented functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging a Production Model\n",
    "\n",
    "## Summary\n",
    "\n",
    "keep humans in the loop\n",
    "\n",
    "Prioritize maintainability\n",
    "\n",
    "Get ready to roll back"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Designing High Performance ML Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aspects of Performance\n",
    "\n",
    "### Training\n",
    "\n",
    "![](tuning_performance.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why distributed training\n",
    "\n",
    "Improving performance alse adds complexity\n",
    "\n",
    "Machine learning gets complex quickly\n",
    "\n",
    "Heterogeneous systems require our code to work anywhere\n",
    "\n",
    "Deep learning works because datasets are large, but the compute required keeps increasing\n",
    "\n",
    "Distributed systems are a necessity for managing complex models with large data volumns\n",
    "\n",
    "### Distributed training architectures\n",
    "\n",
    "**Data Parallelism**\n",
    "\n",
    "Two approaches to Data Parallelism\n",
    "1. Parameter server\n",
    "2. Sync Allreduce\n",
    "\n",
    "![](data_parallelism.png)\n",
    "\n",
    "**Model Parallelism**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Faster input pipelines\n",
    "\n",
    "### Faster input pipelines\n",
    "\n",
    "Reading Data into TensorFlow\n",
    "1. Directly feed from Python\n",
    "2. Native TensorFlow Ops\n",
    "3. Read transformed tf records\n",
    "\n",
    "### Parallel pipelines\n",
    "\n",
    "![](parallelize_file_reading.png)\n",
    "![](parallelize_transformations.png)\n",
    "![](prefetch.png)\n",
    "![](fuse.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data parallelism (All Reduce)\n",
    "\n",
    "**Distribution API Strategy**\n",
    "![](mirroredstrategy.png)\n",
    "\n",
    "**Mirrored Strategy**\n",
    "* No change to the model or training loop\n",
    "* No change to input function (requires tf.data.Dataset)\n",
    "* Checkpoints and summaries are seamless"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Server Approach\n",
    "\n",
    "Data parallelism is a way to incerase training throughput\n",
    "\n",
    "Model Parallelism lets you disribute a model across GPUs\n",
    "\n",
    "Large embedding need multiple machines to map sparse data\n",
    "\n",
    "Estimator train_and_evaluate() handles all this\n",
    "\n",
    "Estimator contains the implementation of three functions: training, evaluation and serving\n",
    "\n",
    "![](estimator_encapsulating.png)\n",
    "\n",
    "train_and_evaluate bundles together a distributed workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "\n",
    "Aspects of performance during inference\n",
    "* QPS\n",
    "* Microservice\n",
    "* Cost\n",
    "\n",
    "![](inference_implement.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid ML System\n",
    "\n",
    "You may not be able to do machine learning soley on Google Cloud\n",
    "* Tied to On-Premise Infrastructure\n",
    "* Multi Cloud System Architecture\n",
    "* Running ML on the edge\n",
    "\n",
    "Kubernetes minimized infrastructure management\n",
    "\n",
    "Kubeflow enables hybrid machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kubeflow\n",
    "\n",
    "### Machine Learning on Hybrid Cloud\n",
    "\n",
    "#### Composability\n",
    "\n",
    "Building a model is only one part of the entire system\n",
    "\n",
    "Each ML Stage is an Independent System\n",
    "\n",
    "Composability is about microservices\n",
    "\n",
    "#### Portability\n",
    "\n",
    "#### Scalability\n",
    "\n",
    "* More accelerators(GPU, TPU)\n",
    "* More CPUs\n",
    "* More disk/networking\n",
    "* More skillsets(data engineers, data scientists)\n",
    "* More teams\n",
    "* More experiments\n",
    "\n",
    "### KubeFlow\n",
    "\n",
    "What's in the box?\n",
    "* Jupyter notebook\n",
    "* Multi-architecture, distributed training\n",
    "* Multi-framework model serving\n",
    "* Examples and walkthroughs for getting started\n",
    "* Ksonnet packaging for customizing it yourself!\n",
    "\n",
    "### Demo: KubeFlow\n",
    "\n",
    "https://github.com/amygdala/code-snippets/tree/master/ml/kubeflow-pipelines\n",
    "\n",
    "KubeFlow Benefits\n",
    "* Portability\n",
    "* Composability and Reproducibility\n",
    "* Scalability\n",
    "* Visualization and Collaboration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimzing TensorFlow for mobile\n",
    "\n",
    "### Embedded Models\n",
    "\n",
    "ML models can help extract meaning from raw data, thus reducing network traffic\n",
    "\n",
    "From mobile devices, we often can't use the microservices approach. Microservices can add unwanted latency\n",
    "\n",
    "In these situations, we'd like to train on the cloud, predict on device\n",
    "\n",
    "### TensorFlow Lite\n",
    "\n",
    "TensorFlow supports multiple mobile platforms\n",
    "\n",
    "TensorFlow Lite\n",
    "* Reduced code footprint\n",
    "* Quantization\n",
    "* Lower precision arithmetric\n",
    "\n",
    "Even though we have talked primarily about prediction on mobile, a new frontier is federated learning\n",
    "\n",
    "### Optimizing for Mobile\n",
    "\n",
    "Large neural networks can be compressed\n",
    "\n",
    "There are several methods to reduce model size\n",
    "* Freeze graph\n",
    "* Transform the graph\n",
    "* Quantize weights and calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrap Up\n",
    "\n",
    "Article: [KubeFlow on GCP](https://cloud.google.com/blog/products/gcp/simplifying-machine-learning-on-open-hybrid-clouds-with-kubeflow.png)\n",
    "\n",
    "Article: [Cloud MLE Architecture Review](https://cloud.google.com/ml-engine/docs/tensorflow/technical-overview.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
