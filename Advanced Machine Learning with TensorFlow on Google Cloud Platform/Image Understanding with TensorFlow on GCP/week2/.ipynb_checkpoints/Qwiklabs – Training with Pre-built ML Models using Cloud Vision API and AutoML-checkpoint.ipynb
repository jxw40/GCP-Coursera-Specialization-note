{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [ML on GCP C8] Training with Pre-built ML Models using Cloud Vision API and AutoML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "Duration is 1 min\n",
    "\n",
    "In this lab, you will experiment with pre-built models so there's no coding. First we'll start with the pre-trained Vision API where we don't need to bring our own data and then we'll progress into AutoML for more sophisticated custom labelling that we need.\n",
    "\n",
    "### What you learn\n",
    "In this lab, you learn how to:\n",
    "\n",
    "* Setup API key for ML Vision API\n",
    "\n",
    "* Invoke the pretrained ML Vision API to classify images\n",
    "\n",
    "* Review label predictions from Vision API\n",
    "\n",
    "* Train and evaluate custom AutoML Vision image classification model\n",
    "\n",
    "* Predict with AutoML on new image\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enable Vision API and create API Key\n",
    "Duration is 1 min\n",
    "\n",
    "To get an API key:\n",
    "\n",
    "### Step 1\n",
    "\n",
    "In your GCP Console, click on the Navigation menu (menu.png), select APIs and services and select Library.\n",
    "\n",
    "### Step 2\n",
    "\n",
    "In the search box, type vision to find the Cloud Vision API and click on the hyperlink.\n",
    "\n",
    "7c01378ef4631c52.png\n",
    "\n",
    "### Step 3\n",
    "\n",
    "Click Enable if necessary.\n",
    "\n",
    "54d492d83efe122b.png\n",
    "\n",
    "### Step 4\n",
    "\n",
    "In your GCP Console, click on the Navigation menu (menu.png), select APIs & Services and select Credentials.\n",
    "\n",
    "### Step 5\n",
    "\n",
    "If you do not already have an API key, click the Create credentials button and select API key. Once created, copy the API key and then click Close.\n",
    "\n",
    "bc4940935c1bef7f.png\n",
    "\n",
    "### Step 6\n",
    "\n",
    "In Cloud Shell, export your API key as environment variable. Be sure to replace <YOUR_API_KEY> with the key you just copied.\n",
    "```\n",
    "export API_KEY=<YOUR_API_KEY>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create storage bucket and store data file\n",
    "\n",
    "Duration is 2 min\n",
    "\n",
    "Create a bucket using the GCP console:\n",
    "\n",
    "### Step 1\n",
    "\n",
    "In your GCP Console, click on the Navigation menu (menu.png), and select Storage.\n",
    "\n",
    "### Step 2\n",
    "\n",
    "Click on Create bucket.\n",
    "\n",
    "### Step 3\n",
    "\n",
    "Choose a Regional bucket and set a unique name (use your project ID because it is unique). Then, click Create.\n",
    "\n",
    "### Step 4\n",
    "\n",
    "Download the image below by right-clicking and saving it locally (save it as cirrus.png):\n",
    "\n",
    "aa9c98d75e404b18.png\n",
    "\n",
    "### Step 5\n",
    "\n",
    "Upload the file you just downloaded into the storage bucket you just created using the upload files button.\n",
    "\n",
    "### Step 6\n",
    "\n",
    "In Cloud Shell, run the command below to make the file publicly accessible.\n",
    "```\n",
    "gsutil acl ch -u AllUsers:R gs://<YOUR-BUCKET>/*\n",
    "```\n",
    "Click the Public link to confirm the file loads correctly (refresh bucket if needed).\n",
    "\n",
    "c5780f58f370ad37.png\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label detection with Vision API\n",
    "### Step 1\n",
    "\n",
    "First, you will create a Vision API request in a json file. Using gcloud or your preferred command line editors (nano, vim, or emacs) create a request.json file and inserting the following:\n",
    "\n",
    "> Note: Replace my-bucket-name with the name of your storage bucket.\n",
    "\n",
    "```\n",
    "{\n",
    "  \"requests\": [\n",
    "      {\n",
    "        \"image\": {\n",
    "          \"source\": {\n",
    "              \"gcsImageUri\": \"gs://my-bucket-name/cirrus.png\"\n",
    "          }\n",
    "        },\n",
    "        \"features\": [\n",
    "          {\n",
    "            \"type\": \"LABEL_DETECTION\",\n",
    "            \"maxResults\": 10\n",
    "          }\n",
    "        ]\n",
    "      }\n",
    "  ]\n",
    "}\n",
    "```\n",
    "Save the file.\n",
    "\n",
    "### Step 2\n",
    "\n",
    "The label detection method will return a list of labels (words) of what's in your image. Call the Vision API with curl:\n",
    "```\n",
    "curl -s -X POST -H \"Content-Type: application/json\" --data-binary @request.json  https://vision.googleapis.com/v1/images:annotate?key=${API_KEY}\n",
    "```\n",
    "Your response should look something like the following:\n",
    "```\n",
    "{\n",
    "        \"responses\": [{\n",
    "                \"labelAnnotations\": [{\n",
    "                        \"mid\": \"/m/01bqvp\",\n",
    "                        \"description\": \"sky\",\n",
    "                        \"score\": 0.9867201,\n",
    "                        \"topicality\": 0.9867201\n",
    "                }, {\n",
    "                        \"mid\": \"/m/0csby\",\n",
    "                        \"description\": \"cloud\",\n",
    "                        \"score\": 0.97132415,\n",
    "                        \"topicality\": 0.97132415\n",
    "                }, {\n",
    "                        \"mid\": \"/m/01g5v\",\n",
    "                        \"description\": \"blue\",\n",
    "                        \"score\": 0.9683707,\n",
    "                        \"topicality\": 0.9683707\n",
    "                }, {\n",
    "                        \"mid\": \"/m/02q7ylj\",\n",
    "                        \"description\": \"daytime\",\n",
    "                        \"score\": 0.9555285,\n",
    "                        \"topicality\": 0.9555285\n",
    "                }, {\n",
    "                        \"mid\": \"/m/01ctsf\",\n",
    "                        \"description\": \"atmosphere\",\n",
    "                        \"score\": 0.92822105,\n",
    "                        \"topicality\": 0.92822105\n",
    "                }, {\n",
    "                        \"mid\": \"/m/0csh5\",\n",
    "                        \"description\": \"cumulus\",\n",
    "                        \"score\": 0.8386173,\n",
    "                        \"topicality\": 0.8386173\n",
    "                }, {\n",
    "                        \"mid\": \"/g/11k2xz7mr\",\n",
    "                        \"description\": \"meteorological phenomenon\",\n",
    "                        \"score\": 0.75660443,\n",
    "                        \"topicality\": 0.75660443\n",
    "                }, {\n",
    "                        \"mid\": \"/m/026fm63\",\n",
    "                        \"description\": \"calm\",\n",
    "                        \"score\": 0.72833425,\n",
    "                        \"topicality\": 0.72833425\n",
    "                }, {\n",
    "                        \"mid\": \"/m/03w43x\",\n",
    "                        \"description\": \"computer wallpaper\",\n",
    "                        \"score\": 0.6601879,\n",
    "                        \"topicality\": 0.6601879\n",
    "                }, {\n",
    "                        \"mid\": \"/m/0d1n2\",\n",
    "                        \"description\": \"horizon\",\n",
    "                        \"score\": 0.63659215,\n",
    "                        \"topicality\": 0.63659215\n",
    "                }]\n",
    "        }]\n",
    "}\n",
    "```\n",
    "Note that the Vision API does recognize it's an image with SKY and CLOUD but the type of cloud is incorrectly labeled as a cumulus cloud. We need a more specific model with our own labeled training data to get a more accurate model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup AutoML Vision\n",
    "AutoML Vision enables you to train machine learning models to classify your images according to your own defined labels. In this section, we will upload images of clouds to Cloud Storage and use them to train a custom model to recognize different types of clouds (cumulus, cumulonimbus, etc.).\n",
    "\n",
    "### Step 1\n",
    "\n",
    "In your GCP Console, click on the Navigation menu (menu.png), click on Vision.\n",
    "\n",
    "72381e48433d551f.png\n",
    "\n",
    "### Step 2\n",
    "\n",
    "Select the GCP account created by qwiklabs (if prompted) and allow AutoML access :\n",
    "\n",
    "e1e349d894d056dd.png\n",
    "\n",
    "### Step 3\n",
    "\n",
    "Click on Get started with AutoML.\n",
    "\n",
    "f728506dd99d1857.png\n",
    "\n",
    "### Step 4\n",
    "\n",
    "Choose the correct GCP project created by qwiklabs and click Continue.\n",
    "\n",
    "e5d39cbdbb996a43.png\n",
    "\n",
    "### Step 5\n",
    "\n",
    "Next, Click on Go To Billing and choose to Go to linked billing account:\n",
    "\n",
    "deb160242e65e406.png\n",
    "\n",
    "3a40cb7562c52efc.png\n",
    "\n",
    "### Step 6\n",
    "\n",
    "Confirm the step was successful.\n",
    "\n",
    "9816b5a6a0248310.png\n",
    "\n",
    "### Step 7\n",
    "\n",
    "Now setup the necessary APIs and service accounts by clicking on Set Up Now.\n",
    "\n",
    "deb160242e65e406.png\n",
    "\n",
    "### Step 8\n",
    "\n",
    "You will be redirected on to the AutoML Vision console.\n",
    "\n",
    "d50aaa6165e60fef.png\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage training files\n",
    "### Step 1\n",
    "\n",
    "Back on your GCP console, check under storage buckets to confirm a new bucket created by AutoML Vision API. The name is similar to your project id, with the suffix vcm (for example : qwiklabs-gcp-dabd0aa7da42381e-vcm).\n",
    "\n",
    "9851fe6befb408d8.png\n",
    "\n",
    "Copy the new bucket name so you can use it in the next step.\n",
    "\n",
    "### Step 2\n",
    "\n",
    "Set the bucket as an environment variable.\n",
    "```\n",
    "export BUCKET=<YOUR_AUTOML_BUCKET>\n",
    "```\n",
    "\n",
    "### Step 3\n",
    "\n",
    "Next, using the gsutil command line utility for Cloud Storage, copy the training images into your bucket:\n",
    "```\n",
    "gsutil -m cp -r gs://automl-codelab-clouds/* gs://${BUCKET}\n",
    "```\n",
    "After the copy, confirm that you have 3 folders in your storage bucket.\n",
    "\n",
    "acba0f20056c1e1d.png\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataset\n",
    "Now that your training data in Cloud Storage, you need a way for AutoML Vision to find them. To do this you'll create a CSV file where each row contains a URL to a training image and the associated label for that image. This CSV file has been created for you, you just need to update it with your bucket name.\n",
    "\n",
    "### Step 1\n",
    "\n",
    "To do that, copy this file to your Cloud Shell instance:\n",
    "```\n",
    "gsutil cp gs://automl-codelab-metadata/data.csv .\n",
    "```\n",
    "\n",
    "### Step 2\n",
    "\n",
    "Then run the following command to update the CSV with the files in your project:\n",
    "```\n",
    "sed -i -e \"s/placeholder/${BUCKET}/g\" ./data.csv\n",
    "```\n",
    "\n",
    "### Step 3\n",
    "\n",
    "Now you're ready to upload this file to your Cloud Storage bucket:\n",
    "```\n",
    "gsutil cp ./data.csv gs://${BUCKET}\n",
    "```\n",
    "\n",
    "Confirm that you see the CSV file in your bucket.\n",
    "\n",
    "### Step 4\n",
    "\n",
    "Navigate back to the AutoML Vision UI.\n",
    "\n",
    "c1d8628f395e3753.png\n",
    "\n",
    "> Note: If you've previously created a dataset with AutoML vision, you will see a list of datasets instead. In this case, click + New Dataset.\n",
    "\n",
    "Type \"clouds\" for the Dataset name.\n",
    "\n",
    "Choose Select a CSV file on Cloud Storage and enter the URL of the file you just uploaded - gs://your-project-name-vcm/data.csv\n",
    "\n",
    "cd7d937018a32bc3.png\n",
    "\n",
    "For this example, leave \"enable multi-label classification\" unchecked. In your own projects, you may want to check this box if you want to assign multiple labels per image.\n",
    "\n",
    "e8ff1ff07b0a1b94.png\n",
    "\n",
    "Select Create Dataset.\n",
    "\n",
    "9526284aab049bcc.png\n",
    "\n",
    "It will take around 2 minutes for your images to finish importing. Once the import has completed, you'll be brought to a page with all the images in your dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect images\n",
    "### Step 1\n",
    "\n",
    "After the import completes, you will see the Images tab.\n",
    "\n",
    "cf21b76c90b91093.png\n",
    "\n",
    "Try filtering by different labels (i.e. click cumulus) to review the training images:\n",
    "\n",
    "44f615aeaccfdd8e.png\n",
    "\n",
    "> Note: If you were building a production model, you'd want at least 100 images per label to ensure high accuracy. This is just a demo so we only used 20 images so that our model will train quickly.\n",
    "\n",
    "### Step 2\n",
    "\n",
    "If any image is labeled incorrectly you can click on them to switch the label or delete the image from your training set:\n",
    "\n",
    "5eb5e78a8ac730c2.png\n",
    "\n",
    "To see a summary of how many images you have for each label, click on Label stats. You should see the following show up on the left side of your browser.\n",
    "\n",
    "label_stats.png\n",
    "\n",
    "> Note: If you are working with a dataset that isn't already labeled, AutoML Vision provides an in-house human labeling service.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train your model\n",
    "You're ready to start training your model! AutoML Vision handles this for you automatically, without requiring you to write any of the model code.\n",
    "\n",
    "### Step 1\n",
    "\n",
    "To train your clouds model, go to the Train tab and click Start Training.\n",
    "\n",
    "Enter a name for your model, or use the default auto-generated name, and click Start Training.\n",
    "\n",
    "1fecfd23c9862dbe.png\n",
    "\n",
    "85f23629111b37e6.png\n",
    "\n",
    "Since this is a small dataset, it will only take around 5 minutes to complete.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate your model\n",
    "### Step 1\n",
    "\n",
    "In the Evaluate tab, you'll see information about AUC, precision and recall of the model.\n",
    "\n",
    "evaluate.png\n",
    "\n",
    "You can also play around with Score threshold:\n",
    "\n",
    "score_threshold.png\n",
    "\n",
    "Finally, scroll down to take a look at the Confusion matrix.\n",
    "\n",
    "confusion_matrix.png\n",
    "\n",
    "All of this provides some common machine learning metrics to evaluate your model accuracy and see where you can improve your training data. Since the focus for this lab was not on accuracy, skip to the prediction section, but feel free to browse the accuracy metrics on your own."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions\n",
    "Now it's time for the most important part: generating predictions on your trained model using data it hasn't seen before.\n",
    "\n",
    "### Step 1\n",
    "\n",
    "Navigate to the Predict tab in the AutoML UI:\n",
    "\n",
    "8c40ba3f466f0af4.png\n",
    "\n",
    "There are a few ways to generate predictions. In this lab, you'll use the UI to upload images. You'll see how your model does classifying these two images (the first is a cirrus cloud, the second is a cumulonimbus).\n",
    "\n",
    "### Step 2\n",
    "\n",
    "Download these images by right-clicking on each of them:\n",
    "\n",
    "a4e6d50183e83703.png\n",
    "\n",
    "1d4aaa17ec62e9ba.png\n",
    "\n",
    "### Step 3\n",
    "\n",
    "Return to the UI, select upload images and upload them to the online prediction UI. When the prediction request completes you should see something like the following:\n",
    "\n",
    "prediction.png\n",
    "\n",
    "Pretty cool - the model classified each type of cloud correctly! Does your trained model do better than the 57% CIRRUS cloud above?\n",
    "\n",
    "> Note: In addition to generating predictions in the AutoML UI, you can also use the REST API or the Python client to make prediction requests on your trained model. Check out the tabs for each to see some sample code. You can try it out by copy/pasting these commands into Cloud Shell and providing an image URL.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
