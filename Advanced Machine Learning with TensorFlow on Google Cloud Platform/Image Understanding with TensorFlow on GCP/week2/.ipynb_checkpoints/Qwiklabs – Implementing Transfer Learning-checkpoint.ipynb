{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [ML on GCP C8] Image Classification Transfer Learning with Inception v3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "In this lab, you carry out a transfer learning example based on Inception-v3 image recognition neural network.\n",
    "\n",
    "### What you learn\n",
    "* How a transfer learning works\n",
    "\n",
    "* How to use Cloud Dataflow for a batch processing of image data\n",
    "\n",
    "* How to use Cloud ML to train a classification model\n",
    "\n",
    "* How to use Cloud ML to provide a prediction API service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "Duration is 2 min\n",
    "\n",
    "Transfer learning is a machine learning method which utilizes a pre-trained neural network. For example, the image recognition model called Inception-v3 consists of two parts:\n",
    "\n",
    "Feature extraction part with a convolutional neural network.\n",
    "Classification part with fully-connected and softmax layers.\n",
    "The pre-trained Inception-v3 model achieves state-of-the-art accuracy for recognizing general objects with 1000 classes, like \"Zebra\", \"Dalmatian\", and \"Dishwasher\". The model extracts general features from input images in the first part and classifies them based on those features in the second part.\n",
    "\n",
    "bfea25ba557fbffc.png\n",
    "\n",
    "In transfer learning, when you build a new model to classify your original dataset, you reuse the feature extraction part and re-train the classification part with your dataset. Since you don't have to train the feature extraction part (which is the most complex part of the model), you can train the model with less computational resources and training time.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "### Step 1: Enable the Cloud Machine Learning Engine API\n",
    "Enable the Cloud Machine Learning Engine API.\n",
    "\n",
    "Navigate to https://console.cloud.google.com/apis/library.\n",
    "\n",
    "Search \"Cloud Machine Learning Engine\"\n",
    "\n",
    "Click on ENABLE button if necessary\n",
    "\n",
    "### Step 2: Enable the Cloud Dataflow API\n",
    "Enable the Cloud Dataflow API.\n",
    "\n",
    "Navigate to https://console.cloud.google.com/apis/library.\n",
    "\n",
    "Search \"Dataflow API\"\n",
    "\n",
    "Click on ENABLE button if necessary\n",
    "\n",
    "### Step 3: Launch CloudShell\n",
    "Now let's open the cloud shell. The cloud shell icon is at the top right:\n",
    "\n",
    "8206c366e1f66c6e.png\n",
    "\n",
    "A cloud shell session will open inside a new frame at the bottom of your browser.\n",
    "\n",
    "29c891701d874b22.png\n",
    "\n",
    "### Step 4: Install Cloud ML SDK\n",
    "Install Cloud ML SDK, and modify the PATH.\n",
    "```\n",
    "sudo pip install google-cloud-dataflow\n",
    "sudo pip install image\n",
    "export PATH=${HOME}/.local/bin:${PATH}\n",
    "```\n",
    "\n",
    "### Step 5: Download tutorial files\n",
    "Download tutorial files and set your current directory.\n",
    "```\n",
    "git clone https://github.com/GoogleCloudPlatform/cloudml-samples\n",
    "cd cloudml-samples/flowers\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn the Dataset\n",
    "Duration is 2 min\n",
    "\n",
    "7221191ec60f55f6.png\n",
    "\n",
    "[Sunflowers](https://www.flickr.com/photos/calliope/1008566138/) by Liz West is licensed under CC BY 2.0\n",
    "\n",
    "You have about 3,600 flower images with five categories. The five category labels are listed in the dictionary file ( [dict.txt](https://storage.cloud.google.com/cloud-ml-data/img/flower_photos/dict.txt)) as below:\n",
    "```\n",
    "daisy\n",
    "dandelion\n",
    "roses\n",
    "sunflowers\n",
    "tulips\n",
    "```\n",
    "This file is used to translate labels into internal ID numbers in the following processes such as daisy=0, dandelion=1, etc.\n",
    "\n",
    "The images are randomly split into a training set with 90% data and an evaluation set with 10% data. Each of them are listed in CSV files:\n",
    "\n",
    "* Training set: [train_set.csv](https://storage.cloud.google.com/cloud-ml-data/img/flower_photos/train_set.csv)\n",
    "* Evaluation set: [eval_set.csv](https://storage.cloud.google.com/cloud-ml-data/img/flower_photos/train_set.csv)\n",
    "\n",
    "The CSV files have the following format consisting of image URIs and labels:\n",
    "```\n",
    "gs://cloud-ml-data/img/flower_photos/dandelion/17388674711_6dca8a2e8b_n.jpg,dandelion\n",
    "gs://cloud-ml-data/img/flower_photos/sunflowers/9555824387_32b151e9b0_m.jpg,sunflowers\n",
    "gs://cloud-ml-data/img/flower_photos/daisy/14523675369_97c31d0b5b.jpg,daisy\n",
    "gs://cloud-ml-data/img/flower_photos/roses/512578026_f6e6f2ad26.jpg,roses\n",
    "gs://cloud-ml-data/img/flower_photos/tulips/497305666_b5d4348826_n.jpg,tulips\n",
    "...\n",
    "```\n",
    "\n",
    "You input these images into the feature extraction part of Inception-v3 which converts the image data into feature vectors consisting of 2048 float values for each image. A feature vector represents the features of the image in an abstract manner. You can better classify images based on these vector values rather than raw image data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Images with Cloud Dataflow\n",
    "Duration is 54 min\n",
    "\n",
    "### Preprocess the Evaluation Set\n",
    "You use Cloud Dataflow to automate the feature extraction process. First, you do it for the evaluation dataset.\n",
    "\n",
    "#### Step 1\n",
    "Set variables to specify the output path and the dictionary file on Cloud Storage.\n",
    "```\n",
    "DICT_FILE=gs://cloud-ml-data/img/flower_photos/dict.txt\n",
    "PROJECT=$(gcloud config list project --format \"value(core.project)\")\n",
    "BUCKET=\"gs://${PROJECT}-flower\"\n",
    "GCS_PATH=\"${BUCKET}/${USER}\"\n",
    "```\n",
    "\n",
    "#### Step 2\n",
    "Create a bucket for the output files and submit a Cloud Dataflow job to process the evaluation set.\n",
    "```\n",
    "gsutil mb $BUCKET\n",
    "python trainer/preprocess.py \\\n",
    "  --input_dict \"$DICT_FILE\" \\\n",
    "  --input_path \"gs://cloud-ml-data/img/flower_photos/eval_set.csv\" \\\n",
    "  --output_path \"${GCS_PATH}/preproc/eval\" \\\n",
    "  --cloud \\\n",
    "  --num_workers 5\n",
    "```\n",
    "By clicking on the Cloud Dataflow menu on the Cloud Console, you find the running job and the link navigates to the data flow graph as below:\n",
    "\n",
    "3a348c6bd13df85b.png\n",
    "\n",
    "> Note: The job takes around 5-30 minutes (depending on the environment) to finish. You can proceed with the next subsection to process the training set in parallel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess the Training Set\n",
    "Since the job takes some time to finish, you open a new tab in the cloud shell and submit another job to process the training set in parallel.\n",
    "\n",
    "#### Step 3\n",
    "Set your current directory in the new tab.\n",
    "```\n",
    "cd $HOME/cloudml-samples/flowers\n",
    "```\n",
    "\n",
    "#### Step 4\n",
    "Set variables to specify the output path and the dictionary file on Cloud Storage.\n",
    "```\n",
    "DICT_FILE=gs://cloud-ml-data/img/flower_photos/dict.txt\n",
    "PROJECT=$(gcloud config list project --format \"value(core.project)\")\n",
    "BUCKET=\"gs://${PROJECT}-flower\"\n",
    "GCS_PATH=\"${BUCKET}/${USER}\"\n",
    "```\n",
    "\n",
    "#### Step 5\n",
    "Submit a Cloud Dataflow job to process the training set.\n",
    "```\n",
    "python trainer/preprocess.py \\\n",
    "  --input_dict \"$DICT_FILE\" \\\n",
    "  --input_path \"gs://cloud-ml-data/img/flower_photos/train_set.csv\" \\\n",
    "  --output_path \"${GCS_PATH}/preproc/train\" \\\n",
    "  --cloud\n",
    "```\n",
    "\n",
    "> Note: The whole process takes around 10 to 45 minutes (depending on the environment) to finish. Please wait for both jobs to finish successfully."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confirm the Preprocessed Files\n",
    "When both jobs finished, the preprocessed files are stored in the following storage paths.\n",
    "\n",
    "#### Step 6\n",
    "Confirm that preprocessed files for the evaluation set are created.\n",
    "```\n",
    "gsutil ls \"${GCS_PATH}/preproc/eval*\"\n",
    "```\n",
    "You see the following files are stored in Cloud Storage.\n",
    "```\n",
    "gs://<Your project ID>-flower/enakai/preproc/eval-00000-of-00043.tfrecord.gz\n",
    "gs://<Your project ID>-flower/enakai/preproc/eval-00001-of-00043.tfrecord.gz\n",
    "gs://<Your project ID>-flower/enakai/preproc/eval-00002-of-00043.tfrecord.gz\n",
    "...\n",
    "```\n",
    "\n",
    "#### Step 7\n",
    "Confirm that preprocessed files for the training set are created.\n",
    "```\n",
    "gsutil ls \"${GCS_PATH}/preproc/train*\"\n",
    "```\n",
    "You see the following files are stored in Cloud Storage.\n",
    "```\n",
    "gs://<Your project ID>-flower/enakai/preproc/train-00000-of-00062.tfrecord.gz\n",
    "gs://<Your project ID>-flower/enakai/preproc/train-00001-of-00062.tfrecord.gz\n",
    "gs://<Your project ID>-flower/enakai/preproc/train-00002-of-00062.tfrecord.gz\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model with Cloud ML\n",
    "Duration is 15 min\n",
    "\n",
    "The next step is to train the classification part of the model using the preprocessed data. The following diagram shows the relationship between the preprocessing and the training.\n",
    "\n",
    "4a077a942db85cb3.png\n",
    "\n",
    "### Step 1\n",
    "Submit a Cloud ML job to train the classification part of the model:\n",
    "```\n",
    "JOB_ID=\"flowers_${USER}_$(date +%Y%m%d_%H%M%S)\"\n",
    "gcloud ml-engine jobs submit training \"$JOB_ID\" \\\n",
    "  --module-name trainer.task \\\n",
    "  --package-path trainer \\\n",
    "  --staging-bucket \"$BUCKET\" \\\n",
    "  --region us-central1 \\\n",
    "  -- \\\n",
    "  --output_path \"${GCS_PATH}/training\" \\\n",
    "  --eval_data_paths \"${GCS_PATH}/preproc/eval*\" \\\n",
    "  --train_data_paths \"${GCS_PATH}/preproc/train*\" \\\n",
    "  --label_count 5\n",
    "```\n",
    "\n",
    "> Note: JOB_ID can be arbitrary but you cannot reuse the same one.\n",
    "\n",
    "### Step 2\n",
    "Click on the Navigation menu > ML Engine on the Cloud Console, find the running job and navigate to the Logs > View Logs to see log messages. The training process takes about 10 minutes. After 1000 training steps, you see the messages as below:\n",
    "```\n",
    "INFO    2016-12-28 14:19:19 +0900       master-replica-0                Eval, step 1000:\n",
    "INFO    2016-12-28 14:19:19 +0900       master-replica-0                - on train set 0.005, 1.000\n",
    "INFO    2016-12-28 14:19:19 +0900       master-replica-0                -- on eval set 0.248, 0.937\n",
    "INFO    2016-12-28 14:19:20 +0900       master-replica-0                Exporting prediction graph to gs://<Your project ID>-flower/<USER>/training/model\n",
    "```\n",
    "This means the model achieved 100% accuracy for the training set and 93.7% accuracy for the evaluation set. (The final accuracy may vary in each training.) The last message indicates that the whole model including the feature extraction part is exported so that you can use the model to classify new images without preprocessing them.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the Trained Model for Predictions\n",
    "Duration is 10 min\n",
    "\n",
    "### Deploy the Trained Model\n",
    "You deploy the exported model to provide a prediction API.\n",
    "\n",
    "#### Step 1\n",
    "Create a prediction API with the specified model name.\n",
    "```\n",
    "MODEL_NAME=flowers\n",
    "gcloud ml-engine models create ${MODEL_NAME} --regions=us-central1\n",
    "```\n",
    "\n",
    "> Note: MODEL_NAME can be arbitrary but you cannot reuse the same one.\n",
    "\n",
    "#### Step 2\n",
    "Create and set a default version of the model with the specified version name.\n",
    "```\n",
    "VERSION_NAME=v1\n",
    "gcloud ml-engine versions create \\\n",
    "  --origin ${GCS_PATH}/training/model/ \\\n",
    "  --model ${MODEL_NAME} \\\n",
    "  ${VERSION_NAME}\n",
    "gcloud ml-engine versions set-default --model ${MODEL_NAME} ${VERSION_NAME}\n",
    "```\n",
    "\n",
    "> Note: VERSION_NAME can be arbitrary but you cannot reuse the same one. The last command is not necessary for the first version since it automatically becomes the default. It's here as a good practice to set the default explicitly.\n",
    "\n",
    "> Important: It may take a few minutes for the deployed model to become ready. Until it becomes ready, it returns 503 error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a JSON Request File\n",
    "Now you can send an image data to get a classification result. First, you need to convert raw image files into a JSON request file.\n",
    "\n",
    "#### Step 3\n",
    "Download two sample images.\n",
    "```\n",
    "gsutil cp gs://cloud-ml-data/img/flower_photos/tulips/4520577328_a94c11e806_n.jpg flower1.jpg\n",
    "gsutil cp gs://cloud-ml-data/img/flower_photos/roses/4504731519_9a260b6607_n.jpg flower2.jpg\n",
    "```\n",
    "\n",
    "#### Step 4\n",
    "Convert the raw images to a single JSON request file.\n",
    "```\n",
    "python -c 'import base64, sys, json; \\\n",
    "  img = base64.b64encode(open(sys.argv[1], \"rb\").read()); \\\n",
    "  print json.dumps({\"key\":\"1\", \"image_bytes\": {\"b64\": img}})' \\\n",
    "  flower1.jpg > request.json\n",
    "python -c 'import base64, sys, json; \\\n",
    "  img = base64.b64encode(open(sys.argv[1], \"rb\").read()); \\\n",
    "  print json.dumps({\"key\":\"2\", \"image_bytes\": {\"b64\": img}})' \\\n",
    "  flower2.jpg >> request.json\n",
    "```\n",
    "\n",
    "In this example, the following images are encoded in base64 and stored in a dictionary associated with key values 1 and 2 respectively.\n",
    "\n",
    "ac9eb40193038e37.png cfcce589272dcfd2.png\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Send a Request to the Prediction API\n",
    "#### Step 5\n",
    "Use the gcloud command to send a request.\n",
    "```\n",
    "gcloud ml-engine predict --model ${MODEL_NAME} --json-instances request.json\n",
    "```\n",
    "The command returns the prediction result as below:\n",
    "```\n",
    "KEY  PREDICTION  SCORES\n",
    "1    4           [1.5868581115796587e-08, 5.666522540082042e-08, 3.1425850011146395e-06, 3.0022348496139273e-10, 0.9999967813491821, 8.086380454130904e-09]\n",
    "2    3           [0.00016239925753325224, 0.007603001315146685, 0.2902684807777405, 0.6873179078102112, 0.01457294262945652, 7.533563621109352e-05]\n",
    "```\n",
    "The returned message shows the key value, prediction and scores. You can use the key value to associate the result with the input image. The prediction is shown in the internal ID as explained in Learn the Dataset section. 4 and 3 correspond to tulips and sunflowers respectively. So the prediction for the second image is incorrect in this example.\n",
    "\n",
    "You can see more details in scores which show the estimated probabilities for each category. For the first image, the score for ID 4 is almost 1.0. On the other hand, for the second image, the score for ID 3 (sunflowers) is about 0.69 whereas the score for ID 2 (roses) is about 0.29. Compared to the first image, you can see that the prediction for the second image is more uncertain.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Duration is 1 min\n",
    "\n",
    "### What we've covered\n",
    "* How a transfer learning works\n",
    "* How to use Cloud Dataflow for a batch processing of image data\n",
    "* How to use Cloud ML to train a classification model\n",
    "* How to use Cloud ML to provide a prediction API service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Job Details\n",
    "\n",
    "2019-02-09 20:17:35.218 HKT\n",
    "master-replica-0\n",
    "Eval, step 1000: - on train set 0.007, 1.000 -- on eval set 0.351, 0.910"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
