{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [ML on GCP C8] Image Classification with a Deep Neural Network Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "Duration is 1 min\n",
    "\n",
    "In this lab, you will define a deep neural network model to do image classification.\n",
    "\n",
    "### What you learn\n",
    "In this lab, you will learn how to:\n",
    "\n",
    "* Import the training dataset of MNIST handwritten images\n",
    "\n",
    "* Reshape and preprocess the image data\n",
    "\n",
    "* Setup your linear classifier model with 10 classes (one for each possible digit 0 through 9)\n",
    "\n",
    "* Define and create your EstimatorSpec in tensorflow to create your custom estimator\n",
    "\n",
    "* Define and run your train_and_evaluate function to train against the input dataset of 60,000 images and evaluate your model's performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST Image Classification\n",
    "Duration is 15 min\n",
    "\n",
    "This lab is organised a little different from lab 1 (linear model). The model code is packaged as a separate python module. You will first complete the model code and then switch to the notebook to set some parameters and run the training job.\n",
    "\n",
    "### Step 1\n",
    "\n",
    "In Cloud Datalab, click on the Home icon, and then navigate to datalab > notebooks > training-data-analyst > courses > machine_learning > deepdive > 08_image > labs > mnistmodel > trainer and open model.py.\n",
    "\n",
    "> Note: If the cloud shell used for running the datalab command is closed or interrupted, the connection to your Cloud Datalab VM will terminate. If that happens, you may be able to reconnect using the command â€˜datalab connect mydatalabvm' in your new Cloud Shell. Once connected, try the above step again.\n",
    "\n",
    "### Step 2\n",
    "\n",
    "Scroll down to dnn_model where you have to replace the #TODO with code to define this dnn model.\n",
    "\n",
    "If you need more help, you may take a look at the complete solution by navigating to : datalab > notebooks > training-data-analyst > courses > machine_learning > deepdive > 08_image > mnistmodel > trainer and open model.py\n",
    "\n",
    "### Step 3\n",
    "\n",
    "Now that you have defined your dnn_model, you are ready to run the training job.\n",
    "\n",
    "In Cloud Datalab, click on the Home icon, and then navigate to datalab > notebooks > training-data-analyst > courses > machine_learning > deepdive > 08_image > labs and open mnist_models.ipynb.\n",
    "\n",
    "### Step 4\n",
    "\n",
    "In Datalab, click on Clear | Clear all Cells.\n",
    "\n",
    "### Step 5\n",
    "\n",
    "In the first cell, make sure to replace the project id, bucket and region with your qwiklabs project id, your bucket, and bucket region respectively. Also, change the MODEL_TYPE to dnn.\n",
    "\n",
    "### Step 6\n",
    "\n",
    "Now read the narrative in the following cells and execute each cell in turn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Job Details\n",
    "\n",
    "2019-02-08 17:02:43.432 HKT\n",
    "master-replica-0\n",
    "Saving dict for global step 10000: accuracy = 0.9704, global_step = 10000, loss = 0.17638418\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
